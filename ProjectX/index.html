<!DOCTYPE html>
<html lang="ru">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Машинное обучение и нейронные сети</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="css/index.css">
</head>

<body>
    <!-- Шапка с навигацией -->
    <header>
        <a href="index.html" class="logo-link">
            <div class="logo">
                <img src="img/Безымянный.png" alt="Логотип">
                <span class="logo-text">Нейронные сети</span>
            </div>
        </a>

        <div class="header-controls">
            <!-- Кнопка музыки -->
            <button class="music-toggle" id="musicToggle">
                <i class="fas fa-music"></i>
            </button>

            <!-- Переключение между темной и светлой темой -->
            <button class="theme-toggle" id="themeToggle">
                <i class="fas fa-moon"></i>
            </button>

            <!-- Кнопка меню для мобильных устройств -->
            <button class="menu-toggle" id="menuToggle">
                <span></span>
                <span></span>
                <span></span>
            </button>

            <!-- Основное меню навигации -->
            <div class="dropdown-menu">
                <button class="dropdown-btn" id="dropdownBtn">
                    Меню <i class="fas fa-chevron-down"></i>
                </button>
                <div class="dropdown-content" id="dropdownContent">
                    <a href="index.html"><i class="fas fa-home"></i> Главная</a>
                    <a href="app.html"><i class="fas fa-rocket"></i> Приложение</a>
                    <a href="#"><i class="fas fa-book"></i> О проекте</a>
                    <a href="#"><i class="fas fa-envelope"></i> Контакты</a>
                </div>
            </div>
        </div>
    </header>

    <!-- YouTube плеер -->
    <div class="youtube-player hidden" id="youtubePlayer">
        <div class="player-header">
            <h3>Фоновая музыка</h3>
            <button class="close-player" id="closePlayer">
                <i class="fas fa-times"></i>
            </button>
        </div>
        <iframe class="youtube-iframe" src="https://www.youtube.com/embed/jfKfPfyJRdk?rel=0&modestbranding=1"
            title="YouTube video player" frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
            allowfullscreen>
        </iframe>
    </div>

    <!-- Боковая панель навигации -->
    <aside class="sidebar" id="sidebar">
        <ul class="sidebar-menu">
            <li class="menu-item">
                <div class="menu-label">
                    <i class="fas fa-robot"></i> Машинное обучение, роль в программировании
                </div>
                <ul class="submenu">
                    <li><a href="#" class="submenu-item" data-target="ml-section">Машинное обучение</a></li>
                    <li><a href="#" class="submenu-item" data-target="section1-1">История развития</a></li>
                    <li><a href="#" class="submenu-item" data-target="section1-2">Основные парадигмы обучения</a></li>
                    <li><a href="#" class="submenu-item" data-target="section1-3">Понятие "чёрного ящика"</a></li>
                    <li><a href="#" class="submenu-item" data-target="section1-4">Цель и задачи исследования</a></li>
                </ul>
            </li>

            <li class="menu-item">
                <div class="menu-label">
                    <i class="fas fa-network-wired"></i> Нейронные сети как инструмент
                </div>
                <ul class="submenu">
                    <li><a href="#" class="submenu-item" data-target="section2-1">Перцептрон и его развитие</a></li>
                    <li><a href="#" class="submenu-item" data-target="section2-2">Многослойный перцептрон (MLP)</a>
                    </li>
                    <li><a href="#" class="submenu-item" data-target="section2-3">Сверточные нейронные сети (CNN)</a>
                    </li>
                    <li><a href="#" class="submenu-item" data-target="section2-4">Основные компоненты нейронных
                            сетей</a></li>
                    <li><a href="#" class="submenu-item" data-target="section2-5">Функции активации</a></li>
                </ul>
            </li>

            <li class="menu-item">
                <div class="menu-label">
                    <i class="fas fa-graduation-cap"></i> Методы обучения нейронных сетей
                </div>
                <ul class="submenu">
                    <li><a href="#" class="submenu-item" data-target="section3-1">Градиентный спуск</a></li>
                    <li><a href="#" class="submenu-item" data-target="section3-2">Обучение с учителем</a></li>
                    <li><a href="#" class="submenu-item" data-target="section3-3">Метод обратного распространения
                            ошибки</a></li>
                </ul>
            </li>
        </ul>
    </aside>

    <!-- Основная область содержимого -->
    <main class="main-content">
        <!-- Приветственный раздел -->
        <section id="welcome-section" class="content-section">
            <h2>Добро пожаловать в мир машинного обучения!</h2>
            <p>Этот сайт предоставляет информацию об основных концепциях машинного обучения и нейронных сетей. Выберите
                интересующую вас тему в боковом меню для получения подробной информации.</p>
            <p>Машинное обучение — это подраздел искусственного интеллекта, который focuses на разработке систем,
                которые обучаются или улучшают свою производительность на основе данных.</p>
        </section>

        <!-- Раздел машинного обучения с навигацией -->
        <section id="ml-section" class="content-section hidden">
            <div class="page-content" id="ml-page-1">
                <h2>Машинное обучение: Введение</h2>

                <div class="image-container">
                    <img src="img/Так можно представлять схематическое изображение модели в уме.png"
                        alt="Машинное обучение" class="content-image">
                    <div class="image-caption">Схематическое изображение модели машинного обучения</div>
                </div>

                <div class="definition">
                    <p>Машинное обучение (МО) — это область знаний и исследований в области искусственного интеллекта,
                        которая занимается разработкой алгоритмов и статистических моделей, которые могут
                        аппроксимировать данные, обучаться на них, обобщать их на невидимые зависимости и, таким
                        образом, выполнять задачи без явных инструкций.</p>
                </div>

                <p>Машинное обучение является ключевой компонентой ИИ, которая позволяет компьютерным программам
                    выполнять задачи без явного программирования, вместо этого полагаясь на закономерности и
                    зависимости, выведенные из данных. Это направление в ИИ, основано на идее того, что системы могут
                    учиться на данные, выявлять закономерности и принимать решения с минимальным вмеранием
                    человека.</p>

                <p>Машинное обучение можно применять в решении различных задач:</p>
                <ul>
                    <li>Предсказывать значения определенной величины на основе набора данных</li>
                    <li>Использовать на веб-сайтах для рекомендации контента или продуктов</li>
                    <li>Помогать выявлять аномалии в финансовых транзакциях и предсказывать рыночные тенденции</li>
                    <li>Распознавать какие-либо объекты и благодаря этому принимать решения</li>
                </ul>
            </div>

            <div class="page-content" id="ml-page-2" style="display: none;">
                <h2>Основные концепции машинного обучения</h2>

                <div class="image-container">
                    <img src="img/Модель машинного обучения.png" alt="Модель машинного обучения" class="content-image">
                    <div class="image-caption">Архитектура модели машинного обучения</div>
                </div>

                <h3>Модель машинного обучения</h3>
                <p>Модель МО — совокупность алгоритмов, параметров и структур данных, которые обеспечивают работу и
                    обучение модели путем изменения ее параметров определенным образом. Другими словами, это система,
                    которая изменяет значения своих параметров, тем самым изменяя свое преобразование входных данных в
                    выходные.</p>

                <h3>Обучение в машинном обучении</h3>
                <p>Обучение в машинном обучении — это итерационный процесс изменения модели используя данные для
                    выявления закономерности, шаблонов и зависимостей между входными и выходными данными, чтобы
                    выполнять конкретные задачи без явного программирования.</p>

                <h3>Данные и признаки</h3>
                <p>Данные — примеры решений, какие-то «подсказки» и всё, что может помочь в процессе обучения:
                    статистика, примеры текстов, расчеты, показатели, исторические события.</p>

                <p>Признаки — независимые (входные) или зависимые (выходные) переменные. Входные признаки подаются на
                    вход модели, после обработки входных данных модель выдает выходные данные (выходные признаки) -
                    ответ модели.</p>
            </div>

            <div class="page-content" id="ml-page-3" style="display: none;">
                <h2>Типы обучения в машинном обучении</h2>

                <div class="image-container">
                    <img src="img/Типы обучения в машинном обучении.png" alt="Типы обучения в ML" class="content-image">
                    <div class="image-caption">Сравнение различных типов обучения</div>
                </div>

                <h3>Обучение с учителем (Supervised Learning)</h3>
                <p>Модель имеет доступ к помеченным данным и обучается на них. Набор данных состоит из пар «входных» и
                    «выходных» данных, в которых выходные данные помечены требуемым значением.</p>

                <h3>Обучение без учителя (Unsupervised Learning)</h3>
                <p>Алгоритм работает с не маркированными данными. Модель на основе заданных алгоритмов выявляет
                    закономерности или классифицирует данные.</p>

                <h3>Обучение с подкреплением (Reinforcement Learning)</h3>
                <p>Модель обучается через «взаимодействие» со средой (окружающей средой), получая награды или штрафы за
                    свои действия.</p>

                <div class="highlight">
                    <p><strong>Применение типов обучения:</strong> Классическое обучение применяется на простых и
                        понятных данных. Обучение с подкреплением используется, когда данных нет, но есть среда, с
                        которой можно взаимодействовать.</p>
                </div>
            </div>

            <div class="section-navigation">
                <button class="nav-btn" id="ml-prev-btn"><i class="fas fa-arrow-left"></i> Назад</button>
                <div class="page-indicator" id="ml-page-indicator">Страница 1 из 3</div>
                <button class="nav-btn" id="ml-next-btn">Вперед <i class="fas fa-arrow-right"></i></button>
            </div>
        </section>

        <!-- Раздел истории развития машинного обучения с навигацией по страницам -->
        <section id="section1-1" class="content-section hidden">
            <!-- Страница 1: Ранние годы -->
            <div class="page-content" id="history-page-1">
                <h2>История развития машинного обучения: Ранние годы (1950-1970)</h2>

                <div class="image-container">
                    <img src="img/Ранняя история машинного обучения.png" alt="Ранняя история машинного обучения"
                        class="content-image">
                    <div class="image-caption">Первые шаги в создании искусственного интеллекта и машинного обучения
                    </div>
                </div>

                <div class="definition">
                    <p>Машинное обучение зародилось в середине XX века как междисциплинарная область на стыке
                        компьютерных наук, статистики и нейробиологии.</p>
                </div>

                <h3>1950-е годы: Зарождение идеи</h3>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-brain"></i>
                        <h4>Алан Тьюринг и "Обучающиеся машины"</h4>
                    </div>
                    <p>В 1950 году Алан Тьюринг опубликовал статью "Вычислительные машины и разум", где предложил
                        концепцию "обучающейся машины" и знаменитый тест Тьюринга для оценки интеллекта машин.</p>
                </div>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-chess-board"></i>
                        <h4>Артур Самуэль и самообучающиеся шашки</h4>
                    </div>
                    <p>В 1959 году Артур Самуэль создал первую самообучающуюся программу для игры в шашки
                        и ввел термин "машинное обучение". Его программа использовала alpha-beta отсечение
                        и могла улучшать свою игру, накапливая опыт.</p>
                </div>

                <h3>1960-е годы: Первые нейронные сети</h3>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-network-wired"></i>
                        <h4>Перцептрон Розенблатта</h4>
                    </div>
                    <p>В 1958 году Фрэнк Розенблатт разработал перцептрон - первую искусственную нейронную сеть,
                        способную к обучению. Перцептрон мог решать задачи линейной классификации и стал фундаментом
                        для будущих разработок в области нейронных сетей.</p>

                    <div class="inventor-card">
                        <img src="img/frank.png" alt="Фрэнк Розенблатт" class="inventor-img">
                        <div class="inventor-info">
                            <h4>Фрэнк Розенблатт (1928-1971)</h4>
                            <p>Американский психолог и пионер в области искусственного интеллекта.
                                Разработал перцептрон в Корнеллской авиационной лаборатории.</p>
                        </div>
                    </div>
                </div>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-book"></i>
                        <h4>Критика Минского и Пейперта</h4>
                    </div>
                    <p>В 1969 году Марвин Минский и Сеймур Пейперт опубликовали книу "Перцептроны",
                        где математически доказали ограничения однослойных перцептронов. Эта работа привела
                        к снижению интереса к нейронным сетям на долгие годы.</p>
                </div>

                <h3>Ключевые достижения этого периода</h3>

                <ul class="breakthrough-list">
                    <li>Создание первых самообучающихся систем</li>
                    <li>Разработка перцептрона - первой нейронной сети</li>
                    <li>Формирование теоретической базы машинного обучения</li>
                    <li>Появление первых алгоритмов обучения</li>
                </ul>
            </div>

            <!-- Страница 2: Возрождение и развитие -->
            <div class="page-content" id="history-page-2" style="display: none;">
                <h2>История развития машинного обучения: Возрождение (1980-2000)</h2>

                <div class="image-container">
                    <img src="img/Vozrojdenie.png" alt="Возрождение машинного обучения" class="content-image">
                    <div class="image-caption">Период возрождения интереса к нейронным сетям и машинному обучению</div>
                </div>

                <div class="definition">
                    <p>1980-е и 1990-е годы стали временем возрождения интереса к нейронным сетям
                        и появления новых фундаментальных алгоритмов машинного обучения.</p>
                </div>

                <h3>1980-е годы: Алгоритм обратного распространения</h3>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-forward"></i>
                        <h4>Обратное распространение ошибки</h4>
                    </div>
                    <p>В 1986 году Дэвид Румельхарт, Джеффри Хинтон и Рональд Вильямс независимо
                        переоткрыли и популяризировали алгоритм обратного распространения ошибки.
                        Это позволило эффективно обучать многослойные нейронные сети и преодолеть
                        ограничения, отмеченные Минским.</p>
                </div>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-microchip"></i>
                        <h4>Специализированные архитектуры</h4>
                    </div>
                    <p>Появились специализированные архитектуры нейронных сетей:</p>
                    <ul>
                        <li>Сверточные нейронные сети (Ян Лекун, 1988)</li>
                        <li>Рекуррентные нейронные сети</li>
                        <li>Сети Хопфилда (Джон Хопфилд, 1982)</li>
                    </ul>
                </div>

                <h3>1990-е годы: Новые алгоритмы и практическое применение</h3>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-chart-line"></i>
                        <h4>Метод опорных векторов (SVM)</h4>
                    </div>
                    <p>В 1995 году Корнелия Кортес и Владимир Вапnik предложили метод опорных векторов
                        (Support Vector Machines), который стал мощным инструментом для классификации
                        и регрессии и широко применяется до сих пор.</p>
                </div>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-memory"></i>
                        <h4>LSTM сети</h4>
                    </div>
                    <p>В 1997 году Зепп Хохрайтер и Юрген Шмидхубер предложили архитектуру
                        долгой краткосрочной памяти (LSTM), которая революционизировала обработку
                        последовательных данных и временных рядов.</p>
                </div>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-random"></i>
                        <h4>Случайные леса и бустинг</h4>
                    </div>
                    <p>Появились ансамблевые методы машинного обучения:</p>
                    <ul>
                        <li>Случайные леса (Лео Брейман, 2001)</li>
                        <li>Адабуст (Йоав Фройнд и Роберт Шапир, 1997)</li>
                        <li>Градиентный бустинг (Джером Фридман, 1999)</li>
                    </ul>
                </div>

                <h3>Практическое применение в 1990-е</h3>

                <ul class="breakthrough-list">
                    <li>Фильтрация спама с помощью наивного байесовского классификатора</li>
                    <li>Распознавание рукописного текста и почтовых индексов</li>
                    <li>Рекомендательные системы (Amazon, Netflix)</li>
                    <li>Системы обнаружения мошенничества</li>
                </ul>
            </div>

            <!-- Страница 3: Современная эра -->
            <div class="page-content" id="history-page-3" style="display: none;">
                <h2>История развития машинного обучения: Современная эра (2000-настоящее время)</h2>

                <div class="image-container">
                    <img src="img/Эра машинного обучения и данных.png" alt="Современная эра машинного обучения"
                        class="content-image">
                    <div class="image-caption">Эра глубокого обучения и больших данных</div>
                </div>

                <div class="definition">
                    <p>С начала 2000-х годов машинное обучение переживает беспрецедентный рост благодаря
                        увеличению вычислительных мощностей, доступности больших данных и развитию новых алгоритмов.</p>
                </div>

                <h3>2000-е годы: Большие данные и глубокое обучение</h3>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-database"></i>
                        <h4>Эра больших данных</h4>
                    </div>
                    <p>Рост объемов данных и вычислительных мощностей позволил обучать более сложные модели.
                        Появление Hadoop (2006) и других технологий big data сделало обработку больших
                        массивов информации доступной.</p>
                </div>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-robot"></i>
                        <h4>Возрождение глубокого обучения</h4>
                    </div>
                    <p>В 2006 году Джеффри Хинтон предложил эффективные алгоритмы для обучения
                        глубоких belief-сетей, что положило начало современной эре глубокого обучения.</p>

                    <div class="inventor-card">
                        <img src="img/djoseph.png" alt="Джеффри Хинтон" class="inventor-img">
                        <div class="inventor-info">
                            <h4>Джеффри Хинтон (род. 1947)</h4>
                            <p>Британско-канадский ученый, пионер глубокого обучения.
                                Лауреат премии Тьюринга 2018 года.</p>
                        </div>
                    </div>
                </div>

                <h3>2010-е годы: Прорывы и широкое применение</h3>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-eye"></i>
                        <h4>AlexNet и революция в компьютерном зрении</h4>
                    </div>
                    <p>В 2012 году AlexNet (разработанная Алексеем Крижевским и др.) значительно
                        превзошла существующие методы на конкурсе ImageNet, что привело к взрывному
                        росту интереса к сверточным нейронным сетям.</p>
                </div>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-chess-knight"></i>
                        <h4>AlphaGo и игры</h4>
                    </div>
                    <p>В 2016 году AlphaGo от DeepMind победила чемпиона мира по игре Го,
                        что стало историческим достижением в области искусственного интеллекта.</p>
                </div>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-language"></i>
                        <h4>Трансформеры и NLP</h4>
                    </div>
                    <p>В 2017 году был представлен архитектура трансформеров, которая произвела
                        революцию в обработке естественного языка и привела к созданию моделей
                        типа BERT, GPT и других.</p>
                </div>

                <h3>2020-е годы: Большие языковые модели и этика ИИ</h3>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-code"></i>
                        <h4>GPT и большие языковые модели</h4>
                    </div>
                    <p>Появление GPT-3 (2020) и более поздних моделей продемонстрировало
                        惊人的 способности больших языковых моделей в генерации текста,
                        переводе и решении сложных задач.</p>
                </div>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-balance-scale"></i>
                        <h4>Этика и ответственный ИИ</h4>
                    </div>
                    <p>Растет внимание к этическим аспектам ИИ, включая вопросы справедливости,
                        прозрачности, конфиденциальности и влияния на общество.</p>
                </div>

                <h3>Текущие тенденции и будущее</h3>

                <ul class="breakthrough-list">
                    <li>Обучение с подкреплением в реальных приложениях</li>
                    <li>Нейроморфные вычисления и специализированные процессоры</li>
                    <li>Квантовое машинное обучение</li>
                    <li>Обучение с небольшим количеством данных (few-shot learning)</li>
                    <li>Мультимодальные модели</li>
                </ul>
            </div>

            <!-- Навигация между страницами -->
            <div class="section-navigation">
                <button class="nav-btn" id="history-prev-btn"><i class="fas fa-arrow-left"></i> Назад</button>
                <div class="page-indicator" id="history-page-indicator">Страница 1 из 3</div>
                <button class="nav-btn" id="history-next-btn">Вперед <i class="fas fa-arrow-right"></i></button>
            </div>
        </section>

        <!-- Раздел основных парадигм обучения -->
        <section id="section1-2" class="content-section hidden">
            <div class="page-content" id="paradigm-page-1">
                <h2>1.2. Основные парадигмы обучения</h2>

                <div class="definition">
                    <p>В машинном обучении существует три фундаментальные парадигмы обучения, которые отличаются
                        подходом к
                        получению знаний из данных и характеру взаимодействия с окружающей средой.</p>
                </div>

                <div class="image-container">
                    <img src="img/machine_obuchenie.png" alt="Парадигмы машинного обучения" class="content-image">
                    <div class="image-caption">Сравнение основных парадигмы машинного обучения</div>
                </div>

                <h3>1. Обучение с учителем (Supervised Learning)</h3>
                <p>Это наиболее распространенный подход, при котором алгоритм обучается на размеченных данных. Каждый
                    пример
                    в обучающей выборке состоит из пары "входные данные - ожидаемый ответ".</p>

                <div class="highlight">
                    <p><strong>Ключевые характеристики:</strong></p>
                    <ul>
                        <li>Наличие помеченных данных (labeled data)</li>
                        <li>Четко определенная целевая переменная</li>
                        <li>Возможность оценки точности predictions</li>
                    </ul>
                </div>

                <p><strong>Основные задачи:</strong></p>
                <ul>
                    <li><strong>Классификация</strong> - отнесение объектов к определенным категориям (спам/не спам,
                        распознавание изображений)</li>
                    <li><strong>Регрессия</strong> - предсказание непрерывных значений (прогнозирование цен,
                        температуры)
                    </li>
                </ul>
            </div>

            <div class="page-content" id="paradigm-page-2" style="display: none;">
                <h3>2. Обучение без учителя (Unsupervised Learning)</h3>
                <p>При этом подходе алгоритм работает с неразмеченными данными и самостоятельно выявляет скрытые
                    закономерности, структуры и взаимосвязи.</p>

                <div class="highlight">
                    <p><strong>Ключевые характеристики:</strong></p>
                    <ul>
                        <li>Отсутствие помеченных данных</li>
                        <li>Самостоятельное выявление patterns</li>
                        <li>Обнаружение скрытых структур</li>
                    </ul>
                </div>

                <p><strong>Основные задачи:</strong></p>
                <ul>
                    <li><strong>Кластеризация</strong> - группировка похожих объектов (сегментация клиентов)</li>
                    <li><strong>Снижение размерности</strong> - упрощение данных при сохранении ключевой информации</li>
                    <li><strong>Обнаружение аномалий</strong> - выявление нестандартных patterns</li>
                </ul>
            </div>

            <div class="page-content" id="paradigm-page-3" style="display: none;">
                <h3>3. Обучение с подкреплением (Reinforcement Learning)</h3>
                <p>Агент обучается через взаимодействие со средой, получая reward за правильные действия и penalty за
                    ошибки. Это процесс обучения методом проб и ошибок.</p>

                <div class="highlight">
                    <p><strong>Ключевые характеристики:</strong></p>
                    <ul>
                        <li>Обучение через взаимодействие со средой</li>
                        <li>Система вознаграждений и штрафов</li>
                        <li>Баланс между исследованием и эксплуатацией</li>
                    </ul>
                </div>

                <p><strong>Основные компоненты:</strong></p>
                <ul>
                    <li><strong>Агент</strong> - обучающаяся система</li>
                    <li><strong>Среда</strong> - внешнее окружение</li>
                    <li><strong>Действия</strong> - возможные операции агента</li>
                    <li><strong>Вознаграждение</strong> - feedback от среды</li>
                </ul>

                <div class="comparison-table">
                    <table>
                        <tr>
                            <th>Парадигма</th>
                            <th>Данные</th>
                            <th>Цель</th>
                            <th>Примеры применения</th>
                        </tr>
                        <tr>
                            <td>С учителем</td>
                            <td>Размеченные</td>
                            <td>Предсказание</td>
                            <td>Распознавание образов, прогнозирование</td>
                        </tr>
                        <tr>
                            <td>Без учителя</td>
                            <td>Неразмеченные</td>
                            <td>Обнаружение закономерностей</td>
                            <td>Кластеризация, анализ данных</td>
                        </tr>
                        <tr>
                            <td>С подкреплением</td>
                            <td>Взаимодействие со средой</td>
                            <td>Оптимальное поведение</td>
                            <td>Робототехника, игры, автономные системы</td>
                        </tr>
                    </table>
                </div>

                <p>На практике эти парадигмы часто комбинируются, создавая гибридные подходы, такие как
                    полу-контролируемое
                    обучение (semi-supervised learning), которое использует как размеченные, так и неразмеченные данные.
                </p>
            </div>

            <div class="section-navigation">
                <button class="nav-btn" id="paradigm-prev-btn"><i class="fas fa-arrow-left"></i> Назад</button>
                <div class="page-indicator" id="paradigm-page-indicator">Страница 1 из 3</div>
                <button class="nav-btn" id="paradigm-next-btn">Вперед <i class="fas fa-arrow-right"></i></button>
            </div>
        </section>

        <!-- Раздел понятия "чёрного ящика" -->
        <section id="section1-3" class="content-section hidden">
            <h2>Понятие "чёрного ящика" в машинном обучении</h2>
            <p>Термин "чёрный ящик" описывает модели машинного обучения, внутренняя работа которых сложна для
                интерпретации человеком. Несмотря на высокую точность предсказаний, понять, как именно модель пришла к
                тому или иному выводу, бывает затруднительно.</p>
            <p>Это особенно характерно для глубоких нейронных сетей, где множество слоев и параметров создают сложные
                взаимодействия, которые трудно проследить и объяснить.</p>
        </section>

        <!-- Раздел цели и задач исследования -->
        <section id="section1-4" class="content-section hidden">
            <h2>Цель и задачи исследования</h2>
            <p>Основной целью исследования является сравнительный анализ трех архитектур нейронных сетей и оценка их
                эффективности при решении конкретных задач.</p>

            <h3>Задачи исследования:</h3>
            <ol>
                <li><strong>Сравнение работоспособности трёх архитектур нейросетей</strong> - анализ возможности каждой
                    архитектуры решать поставленные задачи</li>
                <li><strong>Оценка их эффективности</strong> - измерение точности, скорости обучения и других метрик
                    производительности</li>
                <li><strong>Аналир плюсов и минусов каждой архитектуры</strong> - выявление сильных и слабых сторон
                    каждого подхода</li>
            </ol>

            <div class="image-container">
                <img src="https://via.placeholder.com/800x400?text=Архитектуры+нейросетей"
                    alt="Архитектуры нейронных сетей" class="content-image">
                <div class="image-caption">Сравнение архитектур нейронных сетей</div>
            </div>
        </section>

        <!-- Раздел 2.1: Перцептрон и его развитие -->
        <section id="section2-1" class="content-section hidden">
            <div class="page-content" id="perceptron-page-1">
                <h2>2.1. Перцептрон и его развитие</h2>

                <div class="definition">
                    <p>Перцептрон — это одна из первых моделей искусственного нейрона, предложенная в 1958 году
                        психологом Фрэнком Розенблаттом.</p>
                </div>

                <div class="image-container">
                    <img src="img/perceptron.png" alt="Схема перцептрона" class="content-image">
                    <div class="image-caption">Схематическое изображение перцептрона Розенблатта</div>
                </div>

                <h3>Что такое перцептрон</h3>
                <p>Перцептрон имитирует работу биологических нейронов:</p>

                <ul>
                    <li>принимает на вход несколько сигналов (входные данные)</li>
                    <li>умножает их на веса (важность каждого входа)</li>
                    <li>суммирует</li>
                    <li>пропускает результат через функцию активации (решает, активироваться или нет)</li>
                </ul>

                <p>Идея проста: перцептрон — это линейный классификатор, то есть он делит данные на два класса, проводя
                    прямую (или гиперплоскость в многомерном случае).</p>

                <h3>Ограничения перцептрона</h3>
                <p>Перцептрон умеет решать задачи, которые линейно разделимы (например, AND, OR). Но он не способен
                    решить задачи типа XOR (исключающее ИЛИ), где данные разделяются нелинейно.</p>

                <div class="image-container">
                    <img src="img/xor_problem.png" alt="Проблема XOR" class="content-image">
                    <div class="image-caption">Задача XOR - классический пример нелинейно разделимой проблемы</div>
                </div>

                <p>Эта проблема была подробно описана в книге Мински и Пейперта «Perceptrons» (1969), что привело к
                    «зиме ИИ» — снижению интереса и финансирования исследований в области нейросетей почти на 10–15 лет.
                </p>
            </div>

            <div class="page-content" id="perceptron-page-2" style="display: none;">
                <h3>Развитие идеи перцептрона</h3>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-layer-group"></i>
                        <h4>1. Многослойный перцептрон (MLP, 1980-е)</h4>
                    </div>
                    <ul>
                        <li>Добавили скрытые слои (hidden layers)</li>
                        <li>Появилась возможность решать задачи, которые не разделяются линейно</li>
                        <li>Важный прорыв — алгоритм обратного распространения ошибки (backpropagation) для обучения
                        </li>
                    </ul>
                </div>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-microchip"></i>
                        <h4>2. Нейронные сети 1990-х</h4>
                    </div>
                    <ul>
                        <li>Стали использовать для распознавания речи и изображений</li>
                        <li>Вычислительные мощности и объёмы данных ограничивали развитие</li>
                    </ul>
                </div>

                <div class="era-card">
                    <div class="era-title">
                        <i class="fas fa-brain"></i>
                        <h4>3. Современные глубокие сети (Deep Learning, 2000–2020-е)</h4>
                    </div>
                    <ul>
                        <li>Архитектуры на основе идей перцептрона (CNN, RNN, трансформеры) работают уже с десятками и
                            сотнями слоёв</li>
                        <li>Перцептрон можно считать прародителем всех современных нейросетей</li>
                    </ul>
                </div>

                <h3>Интересные факты</h3>
                <div class="highlight">
                    <ul>
                        <li>Перцептрон Розенблатта изначально был реализован не только программно, но и аппаратно — в
                            виде устройства <strong>Mark I Perceptron</strong>. Оно умело распознавать простые
                            изображения (например, различать треугольник и квадрат).</li>
                        <li>Основная идея "веса" в перцептроне стала фундаментальной: именно на их основе современные
                            модели учатся находить закономерности в данных.</li>
                        <li>Современные трансформеры (например, GPT, BERT) формально тоже основаны на идее "взвешивания
                            входов", только с более сложными функциями (attention = улучшенный способ выделения
                            «важности»).</li>
                    </ul>
                </div>
            </div>

            <div class="page-content" id="perceptron-page-3" style="display: none;">
                <h3>Где используется наследие перцептрона сегодня</h3>

                <div class="image-container">
                    <img src="img/perceptron_applications.png" alt="Применение перцептрона" class="content-image">
                    <div class="image-caption">Современные применения технологий на основе перцептрона</div>
                </div>

                <div class="applications-grid">
                    <div class="app-card">
                        <div class="app-icon">
                            <i class="fas fa-eye"></i>
                        </div>
                        <div class="app-content">
                            <h4>Компьютерное зрение</h4>
                            <p>Распознавание лиц, объектов, сцен</p>
                        </div>
                    </div>

                    <div class="app-card">
                        <div class="app-icon">
                            <i class="fas fa-language"></i>
                        </div>
                        <div class="app-content">
                            <h4>Обработка речи и текста</h4>
                            <p>От Siri и Alexa до ChatGPT</p>
                        </div>
                    </div>

                    <div class="app-card">
                        <div class="app-icon">
                            <i class="fas fa-car"></i>
                        </div>
                        <div class="app-content">
                            <h4>Автопилоты и робототехника</h4>
                            <p>Автономные системы управления</p>
                        </div>
                    </div>

                    <div class="app-card">
                        <div class="app-icon">
                            <i class="fas fa-heartbeat"></i>
                        </div>
                        <div class="app-content">
                            <h4>Биология и медицина</h4>
                            <p>Анализ ДНК, диагностика болезней</p>
                        </div>
                    </div>
                </div>

                <div class="highlight">
                    <p><strong>Историческое значение:</strong> Несмотря на простоту, перцептрон заложил фундаментальные
                        принципы, которые до сих пор используются в современных нейронных сетях. От идеи взвешивания
                        входных сигналов до концепции обучения через коррекцию весов — все эти принципы берут начало в
                        работе Розенблатта.</p>
                </div>

                <div class="inventor-card">
                    <img src="img/frank_rosenblatt.png" alt="Фрэнк Розенблатт" class="inventor-img">
                    <div class="inventor-info">
                        <h4>Фрэнк Розенблатт (1928-1971)</h4>
                        <p>Американский психолог и пионер в области искусственного интеллекта. Разработал перцептрон в
                            Корнеллской авиационной лаборатории. Его работа заложила основы для всего последующего
                            развития нейронных сетей.</p>
                    </div>
                </div>
            </div>

            <div class="section-navigation">
                <button class="nav-btn" id="perceptron-prev-btn"><i class="fas fa-arrow-left"></i> Назад</button>
                <div class="page-indicator" id="perceptron-page-indicator">Страница 1 из 3</div>
                <button class="nav-btn" id="perceptron-next-btn">Вперед <i class="fas fa-arrow-right"></i></button>
            </div>
        </section>

        <!-- Раздел 2.2: Многослойный перцептрон (MLP) -->
        <section id="section2-2" class="content-section hidden">
            <div class="page-content" id="mlp-page-1">
                <h2>2.2. Многослойный перцептрон (MLP)</h2>

                <div class="definition">
                    <p>MLP — это искусственная нейронная сеть, состоящая из нескольких слоёв перцептронов. Это первый
                        шаг от простого перцептрона к глубокому обучению.</p>
                </div>

                <div class="image-container">
                    <img src="img/mlp_architecture.png" alt="Архитектура MLP" class="content-image">
                    <div class="image-caption">Архитектура многослойного перцептрона с входным, скрытыми и выходным
                        слоями</div>
                </div>

                <h3>Определение MLP</h3>
                <p>MLP состоит из трех основных типов слоев:</p>

                <div class="highlight">
                    <ul>
                        <li><strong>Входной слой (input layer)</strong> — получает данные</li>
                        <li><strong>Скрытые слои (hidden layers)</strong> — выполняют преобразования данных, находя
                            более сложные зависимости</li>
                        <li><strong>Выходной слой (output layer)</strong> — выдаёт результат (например, вероятность
                            принадлежности к классу)</li>
                    </ul>
                </div>

                <h3>Почему MLP важен</h3>
                <ul>
                    <li>Решает проблему простого перцептрона (может работать с нелинейно разделимыми данными, например,
                        XOR)</li>
                    <li>Лежит в основе современных нейросетей: сверточные сети (CNN), рекуррентные сети (RNN),
                        трансформеры — это всё расширения идей MLP</li>
                </ul>
            </div>

            <div class="page-content" id="mlp-page-2" style="display: none;">
                <h3>Как работает MLP</h3>

                <div class="process-step">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h4>Линейное преобразование</h4>
                        <p>Каждый нейрон в слое получает значения от предыдущего слоя, умножает их на свои веса и
                            складывает:</p>
                        <div class="formula">
                            $$z = \sum w_i x_i + b$$
                        </div>
                    </div>
                </div>

                <div class="process-step">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h4>Нелинейная функция активации</h4>
                        <p>После суммирования результат пропускается через функцию активации (ReLU, sigmoid, tanh и
                            др.). Это позволяет решать нелинейные задачи.</p>
                    </div>
                </div>

                <div class="process-step">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h4>Передача дальше</h4>
                        <p>Выход нейрона идёт на вход следующему слою.</p>
                    </div>
                </div>

                <div class="process-step">
                    <div class="step-number">4</div>
                    <div class="step-content">
                        <h4>Обучение</h4>
                        <p>Используется алгоритм обратного распространения ошибки (backpropagation) + метод оптимизации
                            (например, градиентный спуск).</p>
                    </div>
                </div>

                <div class="image-container">
                    <img src="img/mlp_working.png" alt="Работа MLP" class="content-image">
                    <div class="image-caption">Процесс прямого распространения сигнала в MLP</div>
                </div>
            </div>

            <div class="page-content" id="mlp-page-3" style="display: none;">
                <h3>Примеры применения MLP</h3>

                <div class="applications-grid">
                    <div class="app-card">
                        <div class="app-icon">
                            <i class="fas fa-camera"></i>
                        </div>
                        <div class="app-content">
                            <h4>Классификация изображений</h4>
                            <p>Распознать, есть ли кот на картинке</p>
                        </div>
                    </div>

                    <div class="app-card">
                        <div class="app-icon">
                            <i class="fas fa-chart-line"></i>
                        </div>
                        <div class="app-content">
                            <h4>Прогнозирование временных рядов</h4>
                            <p>Курс акций, погода</p>
                        </div>
                    </div>

                    <div class="app-card">
                        <div class="app-icon">
                            <i class="fas fa-file-alt"></i>
                        </div>
                        <div class="app-content">
                            <h4>Обработка текста</h4>
                            <p>Определение тональности сообщения</p>
                        </div>
                    </div>
                </div>

                <h3>Важные особенности MLP</h3>

                <div class="features-list">
                    <div class="feature-item">
                        <i class="fas fa-network-wired"></i>
                        <div>
                            <h4>Полносвязная архитектура</h4>
                            <p>MLP — это полносвязная сеть (fully connected): каждый нейрон связан со всеми нейронами
                                предыдущего слоя.</p>
                        </div>
                    </div>

                    <div class="feature-item">
                        <i class="fas fa-layer-group"></i>
                        <div>
                            <h4>Гибкая глубина</h4>
                            <p>Может иметь 1–2 скрытых слоя для простых задач, десятки и сотни слоёв — в глубоких
                                моделях.</p>
                        </div>
                    </div>

                    <div class="feature-item">
                        <i class="fas fa-table"></i>
                        <div>
                            <h4>Универсальность</h4>
                            <p>Хорошо подходит для табличных данных, простых изображений и базовых NLP-задач.</p>
                        </div>
                    </div>
                </div>

                <div class="comparison-table">
                    <table>
                        <tr>
                            <th>Характеристика</th>
                            <th>Простой перцептрон</th>
                            <th>Многослойный перцептрон (MLP)</th>
                        </tr>
                        <tr>
                            <td>Количество слоёв</td>
                            <td>1 слой</td>
                            <td>3+ слоя (входной, скрытые, выходной)</td>
                        </tr>
                        <tr>
                            <td>Способность решать XOR</td>
                            <td>❌ Не может</td>
                            <td>✅ Может</td>
                        </tr>
                        <tr>
                            <td>Выразительная мощность</td>
                            <td>Линейная классификация</td>
                            <td>Универсальный аппроксиматор</td>
                        </tr>
                        <tr>
                            <td>Области применения</td>
                            <td>Ограниченные</td>
                            <td>Широкий спектр задач</td>
                        </tr>
                    </table>
                </div>

                <div class="highlight">
                    <p><strong>Универсальный аппроксиматор:</strong> Теоретически доказано, что MLP с хотя бы одним
                        скрытым слоем и нелинейной функцией активации может аппроксимировать любую непрерывную функцию с
                        любой желаемой точностью.</p>
                </div>
            </div>

            <div class="section-navigation">
                <button class="nav-btn" id="mlp-prev-btn"><i class="fas fa-arrow-left"></i> Назад</button>
                <div class="page-indicator" id="mlp-page-indicator">Страница 1 из 3</div>
                <button class="nav-btn" id="mlp-next-btn">Вперед <i class="fas fa-arrow-right"></i></button>
            </div>
        </section>

        <!-- Раздел 2.3: Сверточные нейронные сети (CNN) -->
        <section id="section2-3" class="content-section hidden">
            <div class="page-content" id="cnn-page-1">
                <h2>2.3. Сверточные нейронные сети (CNN)</h2>

                <div class="definition">
                    <p>Сверточная нейронная сеть — это особый тип нейросети, который специализируется на обработке
                        изображений и данных с пространственной структурой.</p>
                </div>

                <div class="image-container">
                    <img src="img/cnn_architecture.png" alt="Архитектура CNN" class="content-image">
                    <div class="image-caption">Архитектура типичной сверточной нейронной сети</div>
                </div>

                <h3>Что такое CNN</h3>
                <p><strong>Главная идея:</strong> вместо того, чтобы соединять каждый пиксель с каждым нейроном (как в
                    MLP), CNN ищет локальные признаки (например, края, текстуры, формы) с помощью свёрточных фильтров.
                </p>

                <div class="highlight">
                    <p><strong>Ключевое отличие от MLP:</strong></p>
                    <ul>
                        <li><strong>MLP:</strong> Полносвязная архитектура, каждый нейрон связан со всеми входами</li>
                        <li><strong>CNN:</strong> Локальные связи, весовая матрица применяется ко всем областям
                            изображения</li>
                    </ul>
                </div>

                <h3>Преимущества CNN</h3>
                <div class="advantages-grid">
                    <div class="advantage-card">
                        <i class="fas fa-robot"></i>
                        <h4>Автоматическое извлечение признаков</h4>
                        <p>Не нужно вручную придумывать фичи - сеть сама обучается находить важные признаки</p>
                    </div>
                    <div class="advantage-card">
                        <i class="fas fa-th"></i>
                        <h4>Сохранение пространственной структуры</h4>
                        <p>Важно для распознавания объектов и их взаимного расположения</p>
                    </div>
                    <div class="advantage-card">
                        <i class="fas fa-layer-group"></i>
                        <h4>Глубокая архитектура</h4>
                        <p>Могут быть глубокими, с десятками и сотнями специализированных слоёв</p>
                    </div>
                </div>
            </div>

            <div class="page-content" id="cnn-page-2" style="display: none;">
                <h3>Основные компоненты CNN</h3>

                <div class="component-card">
                    <div class="component-header">
                        <div class="component-icon">
                            <i class="fas fa-filter"></i>
                        </div>
                        <div class="component-title">
                            <h4>1. Сверточный слой (Convolutional layer)</h4>
                        </div>
                    </div>
                    <div class="component-content">
                        <ul>
                            <li>Применяет маленькие фильтры (ядра свёртки) к входным данным</li>
                            <li>Фильтры выявляют признаки: линии, углы, текстуры</li>
                            <li>Результат — <em>feature map</em> (карта признаков)</li>
                        </ul>
                        <div class="image-container">
                            <img src="img/convolution_operation.png" alt="Операция свертки" class="content-image">
                            <div class="image-caption">Принцип работы сверточного фильтра</div>
                        </div>
                    </div>
                </div>

                <div class="component-card">
                    <div class="component-header">
                        <div class="component-icon">
                            <i class="fas fa-bolt"></i>
                        </div>
                        <div class="component-title">
                            <h4>2. Функция активации (ReLU, Sigmoid, Tanh)</h4>
                        </div>
                    </div>
                    <div class="component-content">
                        <ul>
                            <li>Добавляет нелинейность, чтобы сеть могла выявлять сложные закономерности</li>
                            <li>Наиболее популярная: ReLU (Rectified Linear Unit)</li>
                        </ul>
                    </div>
                </div>

                <div class="component-card">
                    <div class="component-header">
                        <div class="component-icon">
                            <i class="fas fa-compress-alt"></i>
                        </div>
                        <div class="component-title">
                            <h4>3. Подвыборка / Пулинг (Pooling layer)</h4>
                        </div>
                    </div>
                    <div class="component-content">
                        <ul>
                            <li>Уменьшает размер карты признаков (downsampling), оставляя важные признаки</li>
                            <li>Чаще всего используют <em>max pooling</em> (выбираем максимальное значение в области)
                            </li>
                        </ul>
                        <div class="image-container">
                            <img src="img/max_pooling.png" alt="Max Pooling" class="content-image">
                            <div class="image-caption">Принцип работы max pooling</div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="page-content" id="cnn-page-3" style="display: none;">
                <div class="component-card">
                    <div class="component-header">
                        <div class="component-icon">
                            <i class="fas fa-network-wired"></i>
                        </div>
                        <div class="component-title">
                            <h4>4. Полносвязный слой (Fully connected layer)</h4>
                        </div>
                    </div>
                    <div class="component-content">
                        <ul>
                            <li>После нескольких свёрточных и пулинг-слоёв данные превращаются в вектор</li>
                            <li>Подаются на полносвязный слой для классификации или регрессии</li>
                            <li>Выполняет финальное преобразование признаков в выходные данные</li>
                        </ul>
                    </div>
                </div>

                <h3>Применение CNN</h3>

                <div class="applications-grid">
                    <div class="app-card">
                        <div class="app-icon">
                            <i class="fas fa-eye"></i>
                        </div>
                        <div class="app-content">
                            <h4>Компьютерное зрение</h4>
                            <p>Распознавание лиц, объектов, дорожных знаков</p>
                        </div>
                    </div>

                    <div class="app-card">
                        <div class="app-icon">
                            <i class="fas fa-heartbeat"></i>
                        </div>
                        <div class="app-content">
                            <h4>Медицина</h4>
                            <p>Анализ рентгеновских и МРТ снимков</p>
                        </div>
                    </div>

                    <div class="app-card">
                        <div class="app-icon">
                            <i class="fas fa-car"></i>
                        </div>
                        <div class="app-content">
                            <h4>Автопилоты</h4>
                            <p>Обнаружение пешеходов и препятствий</p>
                        </div>
                    </div>

                    <div class="app-card">
                        <div class="app-icon">
                            <i class="fas fa-paint-brush"></i>
                        </div>
                        <div class="app-content">
                            <h4>Генеративные модели</h4>
                            <p>Создание новых изображений (GAN)</p>
                        </div>
                    </div>
                </div>

                <h3>Процесс работы CNN</h3>

                <div class="process-flow">
                    <div class="flow-step">
                        <div class="flow-icon">📥</div>
                        <div class="flow-text">Входное изображение</div>
                    </div>
                    <div class="flow-arrow">→</div>
                    <div class="flow-step">
                        <div class="flow-icon">🔍</div>
                        <div class="flow-text">Сверточные слои<br>(извлечение признаков)</div>
                    </div>
                    <div class="flow-arrow">→</div>
                    <div class="flow-step">
                        <div class="flow-icon">📊</div>
                        <div class="flow-text">Пулинг слои<br>(уменьшение размерности)</div>
                    </div>
                    <div class="flow-arrow">→</div>
                    <div class="flow-step">
                        <div class="flow-icon">🧠</div>
                        <div class="flow-text">Полносвязные слои<br>(классификация)</div>
                    </div>
                    <div class="flow-arrow">→</div>
                    <div class="flow-step">
                        <div class="flow-icon">🎯</div>
                        <div class="flow-text">Выходной результат</div>
                    </div>
                </div>

                <div class="comparison-table">
                    <table>
                        <tr>
                            <th>Характеристика</th>
                            <th>MLP (Полносвязная сеть)</th>
                            <th>CNN (Сверточная сеть)</th>
                        </tr>
                        <tr>
                            <td>Архитектура</td>
                            <td>Полносвязная</td>
                            <td>Локальные связи + общие веса</td>
                        </tr>
                        <tr>
                            <td>Обработка изображений</td>
                            <td>Неэффективна</td>
                            <td>Высокоэффективна</td>
                        </tr>
                        <tr>
                            <td>Параметры</td>
                            <td>Много (полные связи)</td>
                            <td>Мало (разделяемые веса)</td>
                        </tr>
                        <tr>
                            <td>Инвариантность</td>
                            <td>Низкая</td>
                            <td>Высокая к сдвигам, масштабу</td>
                        </tr>
                    </table>
                </div>

                <div class="highlight">
                    <p><strong>Революция в компьютерном зрении:</strong> CNN произвели революцию в области компьютерного
                        зрения, позволив достичь человеческого уровня точности в задачах распознавания изображений и
                        открыв новые возможности для практического применения искусственного интеллекта.</p>
                </div>
            </div>

            <div class="section-navigation">
                <button class="nav-btn" id="cnn-prev-btn"><i class="fas fa-arrow-left"></i> Назад</button>
                <div class="page-indicator" id="cnn-page-indicator">Страница 1 из 3</div>
                <button class="nav-btn" id="cnn-next-btn">Вперед <i class="fas fa-arrow-right"></i></button>
            </div>
        </section>

        <!-- Раздел 2.4: Основные компоненты нейронных сетей -->
        <section id="section2-4" class="content-section hidden">
            <div class="page-content" id="components-page-1">
                <h2>2.4. Основные компоненты нейронных сетей</h2>

                <div class="definition">
                    <p>Нейронные сети состоят из трех основных типов слоев, каждый из которых выполняет определенную
                        функцию в процессе обработки информации.</p>
                </div>

                <div class="image-container">
                    <img src="img/neural_network_components.png" alt="Компоненты нейронной сети" class="content-image">
                    <div class="image-caption">Схема основных компонентов нейронной сети</div>
                </div>

                <h3>Схема работы нейронной сети</h3>
                <div class="network-scheme">
                    <div class="scheme-item">
                        <div class="scheme-icon">x₁, x₂, x₃</div>
                        <div class="scheme-label">Входные данные</div>
                    </div>
                    <div class="scheme-arrow">→</div>
                    <div class="scheme-item">
                        <div class="scheme-icon">h₁, h₂, h₃...</div>
                        <div class="scheme-label">Скрытые нейроны</div>
                    </div>
                    <div class="scheme-arrow">→</div>
                    <div class="scheme-item">
                        <div class="scheme-icon">y₁, y₂</div>
                        <div class="scheme-label">Выходные результаты</div>
                    </div>
                </div>

                <div class="component-overview">
                    <div class="overview-card">
                        <i class="fas fa-sign-in-alt"></i>
                        <h4>Входной слой</h4>
                        <p>Получает данные из внешнего мира</p>
                    </div>
                    <div class="overview-card">
                        <i class="fas fa-cogs"></i>
                        <h4>Скрытые слои</h4>
                        <p>Обрабатывают и извлекают признаки</p>
                    </div>
                    <div class="overview-card">
                        <i class="fas fa-sign-out-alt"></i>
                        <h4>Выходной слой</h4>
                        <p>Формирует конечный результат</p>
                    </div>
                </div>
            </div>

            <div class="page-content" id="components-page-2" style="display: none;">
                <h3>Входные данные (Input Layer)</h3>

                <div class="component-detail">
                    <div class="detail-header">
                        <i class="fas fa-sign-in-alt"></i>
                        <div>
                            <h4>Что это?</h4>
                            <p>Первый слой сети, который получает данные из внешнего мира.</p>
                        </div>
                    </div>

                    <div class="detail-content">
                        <h5>Примеры входных данных:</h5>
                        <div class="examples-grid">
                            <div class="example-card">
                                <i class="fas fa-image"></i>
                                <div>
                                    <strong>Изображения</strong>
                                    <p>Пиксели изображения (для CNN)</p>
                                </div>
                            </div>
                            <div class="example-card">
                                <i class="fas fa-table"></i>
                                <div>
                                    <strong>Табличные данные</strong>
                                    <p>Характеристики клиента (для MLP)</p>
                                </div>
                            </div>
                            <div class="example-card">
                                <i class="fas fa-font"></i>
                                <div>
                                    <strong>Текст</strong>
                                    <p>Слова в тексте (для NLP)</p>
                                </div>
                            </div>
                        </div>

                        <div class="features-list">
                            <h5>Особенности входного слоя:</h5>
                            <ul>
                                <li>Каждый нейрон входного слоя соответствует одному признаку данных</li>
                                <li>Входной слой не выполняет вычислений, а только передаёт данные дальше</li>
                                <li>Размерность слоя определяется размерностью входных данных</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="image-container">
                    <img src="img/input_layer.png" alt="Входной слой" class="content-image">
                    <div class="image-caption">Структура входного слоя нейронной сети</div>
                </div>
            </div>

            <div class="page-content" id="components-page-3" style="display: none;">
                <h3>Скрытые слои (Hidden Layers)</h3>

                <div class="component-detail">
                    <div class="detail-header">
                        <i class="fas fa-cogs"></i>
                        <div>
                            <h4>Что это?</h4>
                            <p>Слои между входом и выходом, где сеть обрабатывает и извлекает признаки.</p>
                        </div>
                    </div>

                    <div class="detail-content">
                        <h5>Особенности скрытых слоев:</h5>
                        <ul>
                            <li>Каждый нейрон суммирует входы с весами и добавляет смещение (bias)</li>
                            <li>Затем результат пропускается через функцию активации (ReLU, Sigmoid, Tanh)</li>
                            <li>Могут быть один слой или десятки/сотни слоёв в глубоких сетях</li>
                        </ul>

                        <h5>Роль скрытых слоев:</h5>
                        <ul>
                            <li>На скрытых слоях сеть учится находить скрытые зависимости в данных</li>
                            <li>В CNN скрытые слои включают свёрточные слои, которые автоматически выделяют признаки
                            </li>
                            <li>Преобразуют исходные данные в более абстрактные представления</li>
                        </ul>
                    </div>
                </div>

                <div class="depth-comparison">
                    <div class="depth-card">
                        <h4>Мелкая сеть</h4>
                        <div class="depth-visual">
                            <div class="layer">Вход</div>
                            <div class="layer">Скрытый</div>
                            <div class="layer">Выход</div>
                        </div>
                        <p>1-2 скрытых слоя для простых задач</p>
                    </div>
                    <div class="depth-card">
                        <h4>Глубокая сеть</h4>
                        <div class="depth-visual deep">
                            <div class="layer">Вход</div>
                            <div class="layer">Скрытый</div>
                            <div class="layer">Скрытый</div>
                            <div class="layer">Скрытый</div>
                            <div class="layer">Скрытый</div>
                            <div class="layer">Выход</div>
                        </div>
                        <p>Десятки/сотни слоёв для сложных задач</p>
                    </div>
                </div>
            </div>

            <div class="page-content" id="components-page-4" style="display: none;">
                <h3>Выходные данные (Output Layer)</h3>

                <div class="component-detail">
                    <div class="detail-header">
                        <i class="fas fa-sign-out-alt"></i>
                        <div>
                            <h4>Что это?</h4>
                            <p>Последний слой сети, который формирует результат работы сети.</p>
                        </div>
                    </div>

                    <div class="detail-content">
                        <h5>Примеры выходных данных:</h5>
                        <div class="examples-grid">
                            <div class="example-card">
                                <i class="fas fa-tags"></i>
                                <div>
                                    <strong>Классификация</strong>
                                    <p>Вероятность принадлежности к классу</p>
                                </div>
                            </div>
                            <div class="example-card">
                                <i class="fas fa-chart-line"></i>
                                <div>
                                    <strong>Регрессия</strong>
                                    <p>Число или вектор значений</p>
                                </div>
                            </div>
                        </div>

                        <h5>Функции активации выходного слоя:</h5>
                        <div class="activation-types">
                            <div class="activation-card">
                                <h6>Softmax</h6>
                                <p>Для многоклассовой классификации</p>
                                <code>P(class_i) = e<sup>z_i</sup> / ∑e<sup>z_j</sup></code>
                            </div>
                            <div class="activation-card">
                                <h6>Sigmoid</h6>
                                <p>Для бинарной классификации</p>
                                <code>σ(z) = 1 / (1 + e<sup>-z</sup>)</code>
                            </div>
                            <div class="activation-card">
                                <h6>Linear</h6>
                                <p>Для регрессии</p>
                                <code>f(z) = z</code>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="highlight">
                    <p><strong>Важно:</strong> Выбор функции активации на выходном слое зависит от типа решаемой задачи
                        и должен соответствовать формату ожидаемого результата.</p>
                </div>

                <h3>Взаимодействие компонентов</h3>
                <div class="interaction-flow">
                    <div class="flow-stage">
                        <div class="stage-number">1</div>
                        <div class="stage-content">
                            <h4>Входной слой</h4>
                            <p>Принимает сырые данные и нормализует их</p>
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>
                    <div class="flow-stage">
                        <div class="stage-number">2</div>
                        <div class="stage-content">
                            <h4>Скрытые слои</h4>
                            <p>Последовательно преобразуют данные, извлекая признаки</p>
                        </div>
                    </div>
                    <div class="flow-arrow">↓</div>
                    <div class="flow-stage">
                        <div class="stage-number">3</div>
                        <div class="stage-content">
                            <h4>Выходной слой</h4>
                            <p>Формирует конечный результат в нужном формате</p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="section-navigation">
                <button class="nav-btn" id="components-prev-btn"><i class="fas fa-arrow-left"></i> Назад</button>
                <div class="page-indicator" id="components-page-indicator">Страница 1 из 4</div>
                <button class="nav-btn" id="components-next-btn">Вперед <i class="fas fa-arrow-right"></i></button>
            </div>
        </section>

        <!-- Раздел 2.5: Функции активации -->
        <section id="section2-5" class="content-section hidden">
            <div class="page-content" id="activation-page-1">
                <h2>2.5. Функции активации</h2>

                <div class="definition">
                    <p>Функции активации — это ключевой элемент нейронных сетей, который добавляет
                        <strong>нелинейность</strong>. Без них сеть была бы просто линейной моделью и не смогла бы
                        решать сложные задачи.
                    </p>
                </div>

                <div class="image-container">
                    <img src="img/activation_functions.png" alt="Функции активации" class="content-image">
                    <div class="image-caption">Графики основных функций активации</div>
                </div>

                <h3>🔹 Зачем нужны функции активации</h3>

                <div class="purpose-grid">
                    <div class="purpose-card">
                        <div class="purpose-icon">🧠</div>
                        <div class="purpose-content">
                            <h4>Имитация биологических нейронов</h4>
                            <p>Нейрон активируется только при достижении порога, подобно биологическим нейронам</p>
                        </div>
                    </div>
                    <div class="purpose-card">
                        <div class="purpose-icon">📈</div>
                        <div class="purpose-content">
                            <h4>Добавление нелинейности</h4>
                            <p>Позволяет решать задачи типа XOR и распознавать сложные паттерны</p>
                        </div>
                    </div>
                    <div class="purpose-card">
                        <div class="purpose-icon">⚖️</div>
                        <div class="purpose-content">
                            <h4>Нормализация выходов</h4>
                            <p>Преобразует выходы в вероятности или ограниченные диапазоны</p>
                        </div>
                    </div>
                </div>

                <div class="highlight">
                    <p><strong>Без нелинейности:</strong> Многослойная сеть без функций активации была бы эквивалентна
                        однослойному перцептрону, так как композиция линейных функций остаётся линейной функцией.</p>
                </div>
            </div>

            <div class="page-content" id="activation-page-2" style="display: none;">
                <h3>🔹 Основные функции активации</h3>

                <div class="activation-card detailed">
                    <div class="activation-header">
                        <div class="activation-number">1</div>
                        <div class="activation-title">
                            <h4>Step Function (пороговая)</h4>
                        </div>
                    </div>
                    <div class="activation-content">
                        <div class="activation-formula">
                            $$
                            f(x) =
                            \begin{cases}
                            1, & x \geq 0 \\
                            0, & x < 0 \end{cases} $$ </div>
                                <div class="activation-details">
                                    <div class="pros-cons">
                                        <div class="pros">
                                            <h5>Преимущества:</h5>
                                            <ul>
                                                <li>Простая и интуитивно понятная</li>
                                                <li>Использовалась в самом первом перцептроне</li>
                                            </ul>
                                        </div>
                                        <div class="cons">
                                            <h5>Недостатки:</h5>
                                            <ul>
                                                <li>Не подходит для градиентного спуска (недифференцируема)</li>
                                                <li>Нет плавных переходов</li>
                                            </ul>
                                        </div>
                                    </div>
                                </div>
                        </div>
                    </div>

                    <div class="activation-card detailed">
                        <div class="activation-header">
                            <div class="activation-number">2</div>
                            <div class="activation-title">
                                <h4>Sigmoid (сигмоида)</h4>
                            </div>
                        </div>
                        <div class="activation-content">
                            <div class="activation-formula">
                                $$f(x) = \frac{1}{1 + e^{-x}}$$
                            </div>
                            <div class="activation-details">
                                <div class="activation-stats">
                                    <div class="stat">
                                        <span class="stat-label">Диапазон:</span>
                                        <span class="stat-value">(0, 1)</span>
                                    </div>
                                    <div class="stat">
                                        <span class="stat-label">Применение:</span>
                                        <span class="stat-value">Бинарная классификация</span>
                                    </div>
                                </div>
                                <div class="pros-cons">
                                    <div class="pros">
                                        <h5>Преимущества:</h5>
                                        <ul>
                                            <li>Гладкая и дифференцируемая</li>
                                            <li>Хороша для вероятностных выходов</li>
                                        </ul>
                                    </div>
                                    <div class="cons">
                                        <h5>Недостатки:</h5>
                                        <ul>
                                            <li>Эффект vanishing gradient (затухающие градиенты)</li>
                                            <li>Медленное обучение</li>
                                            <li>Выходы не центрированы вокруг нуля</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="activation-card detailed">
                        <div class="activation-header">
                            <div class="activation-number">3</div>
                            <div class="activation-title">
                                <h4>Tanh (гиперболический тангенс)</h4>
                            </div>
                        </div>
                        <div class="activation-content">
                            <div class="activation-formula">
                                $$f(x) = \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$$
                            </div>
                            <div class="activation-details">
                                <div class="activation-stats">
                                    <div class="stat">
                                        <span class="stat-label">Диапазон:</span>
                                        <span class="stat-value">(-1, 1)</span>
                                    </div>
                                    <div class="stat">
                                        <span class="stat-label">Применение:</span>
                                        <span class="stat-value">Скрытые слои</span>
                                    </div>
                                </div>
                                <div class="pros-cons">
                                    <div class="pros">
                                        <h5>Преимущества:</h5>
                                        <ul>
                                            <li>Центрирована вокруг нуля → обучение быстрее</li>
                                            <li>Более сильные градиенты чем у сигмоиды</li>
                                        </ul>
                                    </div>
                                    <div class="cons">
                                        <h5>Недостатки:</h5>
                                        <ul>
                                            <li>Все ещё может страдать от vanishing gradient</li>
                                            <li>Вычислительно сложнее ReLU</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="page-content" id="activation-page-3" style="display: none;">
                    <div class="activation-card detailed">
                        <div class="activation-header">
                            <div class="activation-number">4</div>
                            <div class="activation-title">
                                <h4>ReLU (Rectified Linear Unit)</h4>
                            </div>
                        </div>
                        <div class="activation-content">
                            <div class="activation-formula">
                                $$f(x) = \max(0, x)$$
                            </div>
                            <div class="activation-details">
                                <div class="activation-stats">
                                    <div class="stat">
                                        <span class="stat-label">Диапазон:</span>
                                        <span class="stat-value">[0, ∞)</span>
                                    </div>
                                    <div class="stat">
                                        <span class="stat-label">Применение:</span>
                                        <span class="stat-value">Скрытые слои (самая популярная)</span>
                                    </div>
                                </div>
                                <div class="pros-cons">
                                    <div class="pros">
                                        <h5>Преимущества:</h5>
                                        <ul>
                                            <li>Простая и быстро вычисляется</li>
                                            <li>Не вызывает сильного затухания градиентов</li>
                                            <li>Ускоряет сходимость</li>
                                        </ul>
                                    </div>
                                    <div class="cons">
                                        <h5>Недостатки:</h5>
                                        <ul>
                                            <li>Проблема "dying ReLU" - нейроны могут "умирать"</li>
                                            <li>Не дифференцируема в нуле</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="activation-card detailed">
                        <div class="activation-header">
                            <div class="activation-number">5</div>
                            <div class="activation-title">
                                <h4>Leaky ReLU</h4>
                            </div>
                        </div>
                        <div class="activation-content">
                            <div class="activation-formula">
                                $$
                                f(x) =
                                \begin{cases}
                                x, & x \geq 0 \\
                                0.01x, & x < 0 \end{cases} $$ </div>
                                    <div class="activation-details">
                                        <div class="activation-stats">
                                            <div class="stat">
                                                <span class="stat-label">Диапазон:</span>
                                                <span class="stat-value">(-∞, ∞)</span>
                                            </div>
                                            <div class="stat">
                                                <span class="stat-label">Применение:</span>
                                                <span class="stat-value">Улучшенная версия ReLU</span>
                                            </div>
                                        </div>
                                        <div class="pros-cons">
                                            <div class="pros">
                                                <h5>Преимущества:</h5>
                                                <ul>
                                                    <li>Решает проблему "мертвых" нейронов</li>
                                                    <li>Сохраняет преимущества ReLU</li>
                                                    <li>Градиенты не обнуляются</li>
                                                </ul>
                                            </div>
                                            <div class="cons">
                                                <h5>Недостатки:</h5>
                                                <ul>
                                                    <li>Результаты не всегда consistent</li>
                                                    <li>Дополнительный параметр (наклон)</li>
                                                </ul>
                                            </div>
                                        </div>
                                    </div>
                            </div>
                        </div>

                        <div class="activation-card detailed">
                            <div class="activation-header">
                                <div class="activation-number">6</div>
                                <div class="activation-title">
                                    <h4>Softmax</h4>
                                </div>
                            </div>
                            <div class="activation-content">
                                <div class="activation-formula">
                                    $$f(x_i) = \frac{e^{x_i}}{\sum_j e^{x_j}}$$
                                </div>
                                <div class="activation-details">
                                    <div class="activation-stats">
                                        <div class="stat">
                                            <span class="stat-label">Диапазон:</span>
                                            <span class="stat-value">(0, 1), ∑=1</span>
                                        </div>
                                        <div class="stat">
                                            <span class="stat-label">Применение:</span>
                                            <span class="stat-value">Выходной слой многоклассовой классификации</span>
                                        </div>
                                    </div>
                                    <div class="pros-cons">
                                        <div class="pros">
                                            <h5>Преимущества:</h5>
                                            <ul>
                                                <li>Превращает выходы в вероятности</li>
                                                <li>Сумма выходов равна 1</li>
                                                <li>Идеальна для многоклассовой классификации</li>
                                            </ul>
                                        </div>
                                        <div class="cons">
                                            <h5>Недостатки:</h5>
                                            <ul>
                                                <li>Чувствительна к большим значениям</li>
                                                <li>Вычислительно затратна для большого числа классов</li>
                                            </ul>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="page-content" id="activation-page-4" style="display: none;">
                        <h3>🔹 Сравнение функций активации</h3>

                        <div class="comparison-table">
                            <table>
                                <tr>
                                    <th>Функция</th>
                                    <th>Формула</th>
                                    <th>Диапазон</th>
                                    <th>Применение</th>
                                    <th>Градиенты</th>
                                </tr>
                                <tr>
                                    <td>Step</td>
                                    <td>f(x) = 1 if x≥0 else 0</td>
                                    <td>{0, 1}</td>
                                    <td>Историческое</td>
                                    <td>❌ Нет</td>
                                </tr>
                                <tr>
                                    <td>Sigmoid</td>
                                    <td>1/(1+e⁻ˣ)</td>
                                    <td>(0, 1)</td>
                                    <td>Выход (бинарная)</td>
                                    <td>⚠️ Слабые</td>
                                </tr>
                                <tr>
                                    <td>Tanh</td>
                                    <td>(eˣ-e⁻ˣ)/(eˣ+e⁻ˣ)</td>
                                    <td>(-1, 1)</td>
                                    <td>Скрытые слои</td>
                                    <td>⚠️ Слабые</td>
                                </tr>
                                <tr>
                                    <td>ReLU</td>
                                    <td>max(0, x)</td>
                                    <td>[0, ∞)</td>
                                    <td>Скрытые слои</td>
                                    <td>✅ Сильные</td>
                                </tr>
                                <tr>
                                    <td>Leaky ReLU</td>
                                    <td>x if x≥0 else 0.01x</td>
                                    <td>(-∞, ∞)</td>
                                    <td>Скрытые слои</td>
                                    <td>✅ Сильные</td>
                                </tr>
                                <tr>
                                    <td>Softmax</td>
                                    <td>eˣᵢ/∑eˣʲ</td>
                                    <td>(0, 1), ∑=1</td>
                                    <td>Выход (многокласс)</td>
                                    <td>✅ Хорошие</td>
                                </tr>
                            </table>
                        </div>

                        <h3>🔹 Рекомендации по выбору</h3>

                        <div class="recommendations">
                            <div class="recommendation-card">
                                <div class="rec-icon">🔍</div>
                                <div class="rec-content">
                                    <h4>Скрытые слои</h4>
                                    <p><strong>ReLU</strong> - стандартный выбор для большинства случаев</p>
                                    <p><strong>Leaky ReLU</strong> - если есть проблема "мертвых" нейронов</p>
                                </div>
                            </div>
                            <div class="recommendation-card">
                                <div class="rec-icon">🎯</div>
                                <div class="rec-content">
                                    <h4>Выходной слой</h4>
                                    <p><strong>Sigmoid</strong> - для бинарной классификации</p>
                                    <p><strong>Softmax</strong> - для многоклассовой классификации</p>
                                    <p><strong>Linear</strong> - для регрессии</p>
                                </div>
                            </div>
                            <div class="recommendation-card">
                                <div class="rec-icon">⚠️</div>
                                <div class="rec-content">
                                    <h4>Избегать</h4>
                                    <p><strong>Sigmoid/Tanh</strong> в глубоких сетях из-за vanishing gradient</p>
                                    <p><strong>Step</strong> функции в обучении с градиентным спуском</p>
                                </div>
                            </div>
                        </div>

                        <div class="highlight">
                            <p><strong>Практический совет:</strong> Начинайте с ReLU для скрытых слоев и
                                экспериментируйте с другими функциями только если есть конкретные проблемы с обучением.
                                Для выходного слоя выбор определяется задачей (классификация/регрессия).</p>
                        </div>

                        <h3>🔹 Эволюция функций активации</h3>
                        <div class="evolution-timeline">
                            <div class="timeline-item">
                                <div class="timeline-year">1958</div>
                                <div class="timeline-content">
                                    <h4>Step Function</h4>
                                    <p>Перцептрон Розенблатта</p>
                                </div>
                            </div>
                            <div class="timeline-item">
                                <div class="timeline-year">1980s</div>
                                <div class="timeline-content">
                                    <h4>Sigmoid & Tanh</h4>
                                    <p>Многослойные сети с backpropagation</p>
                                </div>
                            </div>
                            <div class="timeline-item">
                                <div class="timeline-year">2011</div>
                                <div class="timeline-content">
                                    <h4>ReLU</h4>
                                    <p>Прорыв в глубоком обучении</p>
                                </div>
                            </div>
                            <div class="timeline-item">
                                <div class="timeline-year">2013</div>
                                <div class="timeline-content">
                                    <h4>Leaky ReLU</h4>
                                    <p>Решение проблемы "мертвых" нейронов</p>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="section-navigation">
                        <button class="nav-btn" id="activation-prev-btn"><i class="fas fa-arrow-left"></i>
                            Назад</button>
                        <div class="page-indicator" id="activation-page-indicator">Страница 1 из 4</div>
                        <button class="nav-btn" id="activation-next-btn">Вперед <i
                                class="fas fa-arrow-right"></i></button>
                    </div>
        </section>

        <!-- Раздел 3.1: Градиентный спуск -->
        <section id="section3-1" class="content-section hidden">
            <div class="page-content" id="gradient-page-1">
                <h2>3.1. Градиентный спуск</h2>

                <div class="definition">
                    <p>Градиентный спуск — это оптимизационный алгоритм, используемый для минимизации функции потерь
                        путём итеративного движения в направлении, противоположном градиенту функции.</p>
                </div>

                <div class="image-container">
                    <img src="img/gradient_descent.png" alt="Градиентный спуск" class="content-image">
                    <div class="image-caption">Визуализация процесса градиентного спуска</div>
                </div>

                <h3>Цель обучения нейронной сети</h3>
                <p>Обучение сети — это поиск таких <strong>весов</strong> и <strong>смещений (bias)</strong>, чтобы сеть
                    правильно предсказывала выходные данные.</p>

                <div class="math-formula">
                    <div class="formula-item">
                        <span>Вход:</span>
                        <code>$x$</code>
                    </div>
                    <div class="formula-item">
                        <span>Вес:</span>
                        <code>$w$</code>
                    </div>
                    <div class="formula-item">
                        <span>Выход сети:</span>
                        <code>$\hat{y} = f(x, w)$</code>
                    </div>
                    <div class="formula-item">
                        <span>Функция потерь:</span>
                        <code>$L(\hat{y}, y)$</code>
                    </div>
                </div>

                <div class="optimization-goal">
                    <h4>Задача оптимизации:</h4>
                    <div class="formula-large">
                        $$\min_w L(\hat{y}, y)$$
                    </div>
                    <p>Минимизировать функцию потерь по весам сети</p>
                </div>
            </div>

            <div class="page-content" id="gradient-page-2" style="display: none;">
                <h3>Градиентный спуск (Gradient Descent)</h3>
                <p><strong>Идея:</strong> двигаться в направлении наибольшего уменьшения функции потерь, используя её
                    градиент.</p>

                <div class="process-step">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h4>Вычисление градиента</h4>
                        <p>Градиент — это вектор частных производных функции потерь по всем весам сети:</p>
                        <div class="formula">
                            $$\nabla_w L = \left[ \frac{\partial L}{\partial w_1}, \frac{\partial L}{\partial w_2},
                            \dots, \frac{\partial L}{\partial w_n} \right]$$
                        </div>
                        <p>Он показывает, куда и насколько изменить каждый вес, чтобы уменьшить ошибку.</p>
                    </div>
                </div>

                <div class="process-step">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h4>Обновление весов</h4>
                        <div class="formula">
                            $$w := w - \eta \cdot \nabla_w L$$
                        </div>
                        <div class="parameters-list">
                            <div class="parameter">
                                <span class="param-symbol">$w$</span>
                                <span class="param-desc">— текущие веса</span>
                            </div>
                            <div class="parameter">
                                <span class="param-symbol">$\eta$</span>
                                <span class="param-desc">— скорость обучения (learning rate)</span>
                            </div>
                            <div class="parameter">
                                <span class="param-symbol">$\nabla_w L$</span>
                                <span class="param-desc">— градиент функции потерь</span>
                            </div>
                        </div>
                        <p>Таким образом, веса постепенно подбираются так, чтобы сеть училась на примерах.</p>
                    </div>
                </div>

                <div class="image-container">
                    <img src="img/gradient_descent_process.png" alt="Процесс градиентного спуска" class="content-image">
                    <div class="image-caption">Итеративный процесс обновления весов с помощью градиентного спуска</div>
                </div>
            </div>

            <div class="page-content" id="gradient-page-3" style="display: none;">
                <h3>Варианты градиентного спуска</h3>

                <div class="method-comparison">
                    <div class="method-card">
                        <div class="method-header">
                            <div class="method-icon">📊</div>
                            <div class="method-title">
                                <h4>Batch Gradient Descent</h4>
                            </div>
                        </div>
                        <div class="method-content">
                            <p><strong>Описание:</strong> Градиент вычисляется на всей обучающей выборке.</p>
                            <div class="method-stats">
                                <div class="stat">
                                    <span class="stat-label">Скорость:</span>
                                    <span class="stat-value">🔄 Медленная</span>
                                </div>
                                <div class="stat">
                                    <span class="stat-label">Стабильность:</span>
                                    <span class="stat-value">✅ Высокая</span>
                                </div>
                                <div class="stat">
                                    <span class="stat-label">Память:</span>
                                    <span class="stat-value">📈 Высокие требования</span>
                                </div>
                            </div>
                            <div class="method-pros-cons">
                                <div class="pros">
                                    <h5>✓ Преимущества</h5>
                                    <ul>
                                        <li>Стабильная сходимость</li>
                                        <li>Детерминированные обновления</li>
                                    </ul>
                                </div>
                                <div class="cons">
                                    <h5>✗ Недостатки</h5>
                                    <ul>
                                        <li>Медленно для больших данных</li>
                                        <li>Может застревать в локальных минимумах</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="method-card">
                        <div class="method-header">
                            <div class="method-icon">🎯</div>
                            <div class="method-title">
                                <h4>Stochastic Gradient Descent (SGD)</h4>
                            </div>
                        </div>
                        <div class="method-content">
                            <p><strong>Описание:</strong> Градиент вычисляется для одного примера за раз.</p>
                            <div class="method-stats">
                                <div class="stat">
                                    <span class="stat-label">Скорость:</span>
                                    <span class="stat-value">⚡ Быстрая</span>
                                </div>
                                <div class="stat">
                                    <span class="stat-label">Стабильность:</span>
                                    <span class="stat-value">⚠️ Низкая</span>
                                </div>
                                <div class="stat">
                                    <span class="stat-label">Память:</span>
                                    <span class="stat-value">📉 Низкие требования</span>
                                </div>
                            </div>
                            <div class="method-pros-cons">
                                <div class="pros">
                                    <h5>✓ Преимущества</h5>
                                    <ul>
                                        <li>Быстрая сходимость</li>
                                        <li>Может избегать локальных минимумов</li>
                                    </ul>
                                </div>
                                <div class="cons">
                                    <h5>✗ Недостатки</h5>
                                    <ul>
                                        <li>Высокая дисперсия (шум)</li>
                                        <li>Может «прыгать» вокруг оптимума</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="method-card">
                        <div class="method-header">
                            <div class="method-icon">⚖️</div>
                            <div class="method-title">
                                <h4>Mini-batch Gradient Descent</h4>
                            </div>
                        </div>
                        <div class="method-content">
                            <p><strong>Описание:</strong> Градиент вычисляется на небольших пакетах данных (например,
                                32–128 примеров).</p>
                            <div class="method-stats">
                                <div class="stat">
                                    <span class="stat-label">Скорость:</span>
                                    <span class="stat-value">🔸 Умеренная</span>
                                </div>
                                <div class="stat">
                                    <span class="stat-label">Стабильность:</span>
                                    <span class="stat-value">🔸 Средняя</span>
                                </div>
                                <div class="stat">
                                    <span class="stat-label">Память:</span>
                                    <span class="stat-value">🔸 Средние требования</span>
                                </div>
                            </div>
                            <div class="method-pros-cons">
                                <div class="pros">
                                    <h5>✓ Преимущества</h5>
                                    <ul>
                                        <li>Компромисс между скоростью и стабильностью</li>
                                        <li>Хорошо параллелится на GPU</li>
                                    </ul>
                                </div>
                                <div class="cons">
                                    <h5>✗ Недостатки</h5>
                                    <ul>
                                        <li>Требует настройки размера батча</li>
                                        <li>Может требовать больше итераций</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="page-content" id="gradient-page-4" style="display: none;">
                <h3>Улучшения градиентного спуска</h3>

                <div class="improvements-grid">
                    <div class="improvement-card">
                        <div class="improvement-icon">🚀</div>
                        <div class="improvement-content">
                            <h4>Momentum</h4>
                            <p>Учитывает прошлое направление движения, ускоряет обучение.</p>
                            <div class="improvement-formula">
                                $$v_t = \beta v_{t-1} + (1 - \beta) \nabla_w L$$
                                $$w := w - \eta v_t$$
                            </div>
                            <div class="improvement-details">
                                <p><strong>Принцип:</strong> Добавляет "инерцию" к обновлениям, сглаживая колебания.</p>
                                <p><strong>Применение:</strong> Особенно полезно в областях с малым градиентом.</p>
                            </div>
                        </div>
                    </div>

                    <div class="improvement-card">
                        <div class="improvement-icon">📐</div>
                        <div class="improvement-content">
                            <h4>AdaGrad</h4>
                            <p>Адаптивная настройка скорости обучения для каждого параметра.</p>
                            <div class="improvement-formula">
                                $$G_t = G_{t-1} + (\nabla_w L)^2$$
                                $$w := w - \frac{\eta}{\sqrt{G_t + \epsilon}} \nabla_w L$$
                            </div>
                            <div class="improvement-details">
                                <p><strong>Принцип:</strong> Уменьшает LR для часто обновляемых параметров.</p>
                                <p><strong>Особенность:</strong> Может слишком агрессивно уменьшать LR.</p>
                            </div>
                        </div>
                    </div>

                    <div class="improvement-card">
                        <div class="improvement-icon">⚡</div>
                        <div class="improvement-content">
                            <h4>RMSProp</h4>
                            <p>Улучшение AdaGrad с экспоненциальным скользящим средним.</p>
                            <div class="improvement-formula">
                                $$G_t = \beta G_{t-1} + (1 - \beta)(\nabla_w L)^2$$
                                $$w := w - \frac{\eta}{\sqrt{G_t + \epsilon}} \nabla_w L$$
                            </div>
                            <div class="improvement-details">
                                <p><strong>Принцип:</strong> Решает проблему агрессивного уменьшения LR.</p>
                                <p><strong>Преимущество:</strong> Лучшая адаптация к изменяющимся градиентам.</p>
                            </div>
                        </div>
                    </div>

                    <div class="improvement-card">
                        <div class="improvement-icon">🤖</div>
                        <div class="improvement-content">
                            <h4>Adam</h4>
                            <p>Комбинация Momentum и RMSProp (наиболее популярный).</p>
                            <div class="improvement-formula">
                                $$m_t = \beta_1 m_{t-1} + (1 - \beta_1) \nabla_w L$$
                                $$v_t = \beta_2 v_{t-1} + (1 - \beta_2)(\nabla_w L)^2$$
                                $$w := w - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}$$
                            </div>
                            <div class="improvement-details">
                                <p><strong>Принцип:</strong> Сочетает преимущества адаптивного LR и momentum.</p>
                                <p><strong>Рекомендация:</strong> Стандартный выбор для большинства задач.</p>
                            </div>
                        </div>
                    </div>
                </div>

                <h3>Сравнение оптимизаторов</h3>
                <div class="comparison-table">
                    <table>
                        <tr>
                            <th>Оптимизатор</th>
                            <th>Скорость</th>
                            <th>Стабильность</th>
                            <th>Настройка LR</th>
                            <th>Рекомендация</th>
                        </tr>
                        <tr>
                            <td>SGD</td>
                            <td>Медленная</td>
                            <td>Высокая</td>
                            <td>Требует точной настройки</td>
                            <td>Для простых задач</td>
                        </tr>
                        <tr>
                            <td>SGD + Momentum</td>
                            <td>Быстрая</td>
                            <td>Средняя</td>
                            <td>Требует настройки</td>
                            <td>Для плавных поверхностей</td>
                        </tr>
                        <tr>
                            <td>Adam</td>
                            <td>Очень быстрая</td>
                            <td>Высокая</td>
                            <td>Автоматическая</td>
                            <td>Стандартный выбор</td>
                        </tr>
                        <tr>
                            <td>RMSProp</td>
                            <td>Быстрая</td>
                            <td>Высокая</td>
                            <td>Автоматическая</td>
                            <td>Для RNN и нестационарных задач</td>
                        </tr>
                    </table>
                </div>

                <div class="highlight">
                    <p><strong>Практический совет:</strong> Начинайте с Adam для большинства задач. Если сеть не
                        сходится или показывает плохие результаты, попробуйте SGD с настроенным learning rate для более
                        стабильного, но медленного обучения.</p>
                </div>
            </div>

            <div class="section-navigation">
                <button class="nav-btn" id="gradient-prev-btn"><i class="fas fa-arrow-left"></i> Назад</button>
                <div class="page-indicator" id="gradient-page-indicator">Страница 1 из 4</div>
                <button class="nav-btn" id="gradient-next-btn">Вперед <i class="fas fa-arrow-right"></i></button>
            </div>
        </section>

        <!-- Раздел 3.2: Обучение с учителем -->
        <section id="section3-2" class="content-section hidden">
            <div class="page-content" id="supervised-page-1">
                <h2>3.2. Обучение с учителем</h2>

                <div class="definition">
                    <p>Обучение с учителем — это метод, при котором нейронная сеть обучается на подготовленных данных с
                        известными правильными ответами (<strong>метками, labels</strong>).</p>
                </div>

                <div class="image-container">
                    <img src="img/supervised_learning.png" alt="Обучение с учителем" class="content-image">
                    <div class="image-caption">Схема процесса обучения с учителем</div>
                </div>

                <h3>Определение</h3>

                <div class="data-structure">
                    <div class="data-formula">
                        <h4>Данные для обучения:</h4>
                        <div class="formula">
                            $(x_1, y_1), (x_2, y_2), …, (x_n, y_n)$
                        </div>
                    </div>
                    <div class="data-explanation">
                        <div class="variable">
                            <span class="var-symbol">$x_i$</span>
                            <span class="var-desc">— входные признаки</span>
                        </div>
                        <div class="variable">
                            <span class="var-symbol">$y_i$</span>
                            <span class="var-desc">— правильный ответ (класс, число и т.д.)</span>
                        </div>
                    </div>
                </div>

                <div class="learning-goal">
                    <h4>Цель обучения:</h4>
                    <div class="goal-formula">
                        Сеть должна научиться предсказывать $y$ по $x$
                    </div>
                    <p>Минимизировать разницу между предсказаниями сети и реальными значениями</p>
                </div>

                <h3>Отличительные черты</h3>
                <div class="features-grid">
                    <div class="feature-card">
                        <div class="feature-icon">🏷️</div>
                        <div class="feature-content">
                            <h4>Размеченные данные</h4>
                            <p>Данные должны быть <strong>labeled</strong> - иметь правильные ответы</p>
                        </div>
                    </div>
                    <div class="feature-card">
                        <div class="feature-icon">👨‍🏫</div>
                        <div class="feature-content">
                            <h4>Обучение по примерам</h4>
                            <p>«Учитель» показывает правильный ответ для каждого примера</p>
                        </div>
                    </div>
                    <div class="feature-card">
                        <div class="feature-icon">🔮</div>
                        <div class="feature-content">
                            <h4>Обобщение знаний</h4>
                            <p>Сеть может применять знания к новым, невиданным данным</p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="page-content" id="supervised-page-2" style="display: none;">
                <h3>Как работает обучение с учителем</h3>

                <div class="learning-process">
                    <div class="process-step detailed">
                        <div class="step-number">1</div>
                        <div class="step-content">
                            <h4>Прямой проход (Forward Pass)</h4>
                            <p>Входные данные проходят через нейронную сеть → получаем предсказание $\hat{y}$.</p>
                            <div class="process-visual">
                                <span class="input">$x$</span>
                                <span class="arrow">→</span>
                                <span class="network">Нейронная сеть</span>
                                <span class="arrow">→</span>
                                <span class="output">$\hat{y}$</span>
                            </div>
                        </div>
                    </div>

                    <div class="process-step detailed">
                        <div class="step-number">2</div>
                        <div class="step-content">
                            <h4>Вычисление ошибки (Loss)</h4>
                            <p>Сравниваем предсказание $\hat{y}$ с правильным ответом $y$ через функцию потерь
                                $L(\hat{y}, y)$.</p>
                            <div class="loss-formula">
                                $$L(\hat{y}, y) = \text{разница между предсказанием и истиной}$$
                            </div>
                        </div>
                    </div>

                    <div class="process-step detailed">
                        <div class="step-number">3</div>
                        <div class="step-content">
                            <h4>Обратное распространение ошибки (Backpropagation)</h4>
                            <p>Вычисляем градиенты функции потерь по весам сети.</p>
                            <div class="gradient-formula">
                                $$\nabla_w L = \left[ \frac{\partial L}{\partial w_1}, \frac{\partial L}{\partial w_2},
                                \dots \right]$$
                            </div>
                        </div>
                    </div>

                    <div class="process-step detailed">
                        <div class="step-number">4</div>
                        <div class="step-content">
                            <h4>Обновление весов (Gradient Descent)</h4>
                            <p>Подбираем веса так, чтобы уменьшить ошибку на обучающей выборке.</p>
                            <div class="update-formula">
                                $$w := w - \eta \cdot \nabla_w L$$
                            </div>
                        </div>
                    </div>

                    <div class="process-step detailed">
                        <div class="step-number">5</div>
                        <div class="step-content">
                            <h4>Повторение процесса</h4>
                            <p>Процесс продолжается, пока ошибка на обучающей выборке не станет минимальной или не
                                достигнет заданного уровня.</p>
                            <div class="iteration-info">
                                <span class="iteration-icon">🔄</span>
                                <span>Многократное повторение для улучшения точности</span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="page-content" id="supervised-page-3" style="display: none;">
                <h3>Примеры применения</h3>

                <div class="applications-category">
                    <div class="category-header">
                        <div class="category-icon">🖼️</div>
                        <div class="category-title">
                            <h4>Классификация изображений</h4>
                        </div>
                    </div>
                    <div class="category-content">
                        <div class="examples-list">
                            <div class="example-item">
                                <span class="example-badge">MNIST</span>
                                <span class="example-text">Распознавание рукописных цифр</span>
                            </div>
                            <div class="example-item">
                                <span class="example-badge">ImageNet</span>
                                <span class="example-text">Распознавание объектов на фото</span>
                            </div>
                            <div class="example-item">
                                <span class="example-badge">Face Recognition</span>
                                <span class="example-text">Идентификация лиц</span>
                            </div>
                        </div>
                        <div class="category-image">
                            <img src="img/image_classification.png" alt="Классификация изображений"
                                class="content-image">
                        </div>
                    </div>
                </div>

                <div class="applications-category">
                    <div class="category-header">
                        <div class="category-icon">📝</div>
                        <div class="category-title">
                            <h4>Классификация текста</h4>
                        </div>
                    </div>
                    <div class="category-content">
                        <div class="examples-list">
                            <div class="example-item">
                                <span class="example-badge">Спам-фильтр</span>
                                <span class="example-text">Определение спам-писем</span>
                            </div>
                            <div class="example-item">
                                <span class="example-badge">Анализ тональности</span>
                                <span class="example-text">Определение эмоциональной окраски</span>
                            </div>
                            <div class="example-item">
                                <span class="example-badge">Категоризация</span>
                                <span class="example-text">Отнесение текстов к темам</span>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="applications-category">
                    <div class="category-header">
                        <div class="category-icon">📊</div>
                        <div class="category-title">
                            <h4>Регрессия</h4>
                        </div>
                    </div>
                    <div class="category-content">
                        <div class="examples-list">
                            <div class="example-item">
                                <span class="example-badge">Прогнозирование цен</span>
                                <span class="example-text">Цена дома по параметрам (площадь, район, этаж)</span>
                            </div>
                            <div class="example-item">
                                <span class="example-badge">Медицинская диагностика</span>
                                <span class="example-text">Прогноз заболевания по симптомам</span>
                            </div>
                            <div class="example-item">
                                <span class="example-badge">Финансовые прогнозы</span>
                                <span class="example-text">Предсказание курсов акций</span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="page-content" id="supervised-page-4" style="display: none;">
                <h3>Типы задач обучения с учителем</h3>

                <div class="task-types">
                    <div class="task-card">
                        <div class="task-header">
                            <div class="task-icon">🏷️</div>
                            <div class="task-title">
                                <h4>Классификация</h4>
                            </div>
                        </div>
                        <div class="task-content">
                            <p><strong>Цель:</strong> Отнесение объектов к определенным категориям</p>
                            <div class="task-examples">
                                <h5>Примеры:</h5>
                                <ul>
                                    <li>Спам/не спам</li>
                                    <li>Кошка/собака/птица</li>
                                    <li>Положительный/отрицательный отзыв</li>
                                </ul>
                            </div>
                            <div class="task-metrics">
                                <h5>Метрики оценки:</h5>
                                <div class="metrics-list">
                                    <span class="metric">Accuracy</span>
                                    <span class="metric">Precision</span>
                                    <span class="metric">Recall</span>
                                    <span class="metric">F1-score</span>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="task-card">
                        <div class="task-header">
                            <div class="task-icon">📈</div>
                            <div class="task-title">
                                <h4>Регрессия</h4>
                            </div>
                        </div>
                        <div class="task-content">
                            <p><strong>Цель:</strong> Предсказание непрерывных численных значений</p>
                            <div class="task-examples">
                                <h5>Примеры:</h5>
                                <ul>
                                    <li>Цена недвижимости</li>
                                    <li>Температура на завтра</li>
                                    <li>Время доставки</li>
                                </ul>
                            </div>
                            <div class="task-metrics">
                                <h5>Метрики оценки:</h5>
                                <div class="metrics-list">
                                    <span class="metric">MSE</span>
                                    <span class="metric">MAE</span>
                                    <span class="metric">R²</span>
                                    <span class="metric">RMSE</span>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <h3>Процесс обучения на практике</h3>
                <div class="training-pipeline">
                    <div class="pipeline-step">
                        <div class="step-icon">📥</div>
                        <div class="step-content">
                            <h5>1. Сбор данных</h5>
                            <p>Подготовка размеченного набора данных</p>
                        </div>
                    </div>
                    <div class="pipeline-arrow">→</div>
                    <div class="pipeline-step">
                        <div class="step-icon">⚙️</div>
                        <div class="step-content">
                            <h5>2. Предобработка</h5>
                            <p>Нормализация, аугментация данных</p>
                        </div>
                    </div>
                    <div class="pipeline-arrow">→</div>
                    <div class="pipeline-step">
                        <div class="step-icon">🏗️</div>
                        <div class="step-content">
                            <h5>3. Выбор модели</h5>
                            <p>Архитектура нейронной сети</p>
                        </div>
                    </div>
                    <div class="pipeline-arrow">→</div>
                    <div class="pipeline-step">
                        <div class="step-icon">🎯</div>
                        <div class="step-content">
                            <h5>4. Обучение</h5>
                            <p>Минимизация функции потерь</p>
                        </div>
                    </div>
                    <div class="pipeline-arrow">→</div>
                    <div class="pipeline-step">
                        <div class="step-icon">📊</div>
                        <div class="step-content">
                            <h5>5. Оценка</h5>
                            <p>Тестирование на новых данных</p>
                        </div>
                    </div>
                </div>

                <div class="highlight">
                    <p><strong>Ключевое преимущество:</strong> Обучение с учителем позволяет создавать модели, которые
                        могут обобщать знания и делать точные предсказания на новых данных, которых они никогда не
                        видели во время обучения.</p>
                </div>

                <div class="best-practices">
                    <h4>Лучшие практики</h4>
                    <div class="practices-grid">
                        <div class="practice-item">
                            <div class="practice-icon">📏</div>
                            <div class="practice-content">
                                <h5>Качество данных</h5>
                                <p>Разметка должна быть точной и последовательной</p>
                            </div>
                        </div>
                        <div class="practice-item">
                            <div class="practice-icon">⚖️</div>
                            <div class="practice-content">
                                <h5>Сбалансированность</h5>
                                <p>Классы должны быть представлены пропорционально</p>
                            </div>
                        </div>
                        <div class="practice-item">
                            <div class="practice-icon">🔍</div>
                            <div class="practice-content">
                                <h5>Валидация</h5>
                                <p>Разделение на обучающую и тестовую выборки</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="section-navigation">
                <button class="nav-btn" id="supervised-prev-btn"><i class="fas fa-arrow-left"></i> Назад</button>
                <div class="page-indicator" id="supervised-page-indicator">Страница 1 из 4</div>
                <button class="nav-btn" id="supervised-next-btn">Вперед <i class="fas fa-arrow-right"></i></button>
            </div>
        </section>

        <!-- Раздел 3.3: Метод обратного распространения ошибки -->
        <section id="section3-3" class="content-section hidden">
            <div class="page-content" id="backprop-page-1">
                <h2>3.3. Метод обратного распространения ошибки</h2>

                <div class="definition">
                    <p>Обратное распространение ошибки — это алгоритм, который позволяет нейронной сети вычислять
                        градиенты функции потерь по всем весам и корректировать их, чтобы минимизировать ошибку сети.
                    </p>
                </div>

                <div class="image-container">
                    <img src="img/backpropagation.png" alt="Обратное распространение ошибки" class="content-image">
                    <div class="image-caption">Схема алгоритма обратного распространения ошибки</div>
                </div>

                <h3>Определение</h3>

                <div class="key-points">
                    <div class="point-card">
                        <div class="point-icon">🔄</div>
                        <div class="point-content">
                            <h4>Используется с градиентным спуском</h4>
                            <p>Составляет основу процесса обучения нейронных сетей</p>
                        </div>
                    </div>
                    <div class="point-card">
                        <div class="point-icon">🏗️</div>
                        <div class="point-content">
                            <h4>Позволяет обучать многослойные сети</h4>
                            <p>Ключевой алгоритм для MLP и глубоких сетей</p>
                        </div>
                    </div>
                    <div class="point-card">
                        <div class="point-icon">🎯</div>
                        <div class="point-content">
                            <h4>Автоматическое вычисление градиентов</h4>
                            <p>Эффективно рассчитывает производные для всех параметров</p>
                        </div>
                    </div>
                </div>

                <div class="highlight">
                    <p><strong>Историческое значение:</strong> Backpropagation стал прорывом в 1980-х годах, позволившим
                        эффективно обучать многослойные нейронные сети и открывшим путь к современному глубокому
                        обучению.</p>
                </div>
            </div>

            <div class="page-content" id="backprop-page-2" style="display: none;">
                <h3>Идея метода</h3>

                <div class="algorithm-steps">
                    <div class="algorithm-step">
                        <div class="step-header">
                            <div class="step-number">1</div>
                            <div class="step-title">
                                <h4>Прямой проход (Forward Pass)</h4>
                            </div>
                        </div>
                        <div class="step-content">
                            <p>Входные данные проходят через все слои сети → получаем выход $\hat{y}$.</p>
                            <div class="step-visual">
                                <div class="forward-flow">
                                    <span class="flow-item">Вход $x$</span>
                                    <span class="flow-arrow">→</span>
                                    <span class="flow-item">Слой 1</span>
                                    <span class="flow-arrow">→</span>
                                    <span class="flow-item">Слой 2</span>
                                    <span class="flow-arrow">→</span>
                                    <span class="flow-item">...</span>
                                    <span class="flow-arrow">→</span>
                                    <span class="flow-item">Выход $\hat{y}$</span>
                                </div>
                            </div>
                            <p>Вычисляется функция потерь $L(\hat{y}, y)$ — мера ошибки сети.</p>
                        </div>
                    </div>

                    <div class="algorithm-step">
                        <div class="step-header">
                            <div class="step-number">2</div>
                            <div class="step-title">
                                <h4>Обратный проход (Backward Pass)</h4>
                            </div>
                        </div>
                        <div class="step-content">
                            <p>Ошибка распространяется обратно по сети от выходного слоя к входному.</p>
                            <div class="step-visual">
                                <div class="backward-flow">
                                    <span class="flow-item">Ошибка $\frac{\partial L}{\partial y}$</span>
                                    <span class="flow-arrow">←</span>
                                    <span class="flow-item">Слой N</span>
                                    <span class="flow-arrow">←</span>
                                    <span class="flow-item">Слой N-1</span>
                                    <span class="flow-arrow">←</span>
                                    <span class="flow-item">...</span>
                                    <span class="flow-arrow">←</span>
                                    <span class="flow-item">Слой 1</span>
                                </div>
                            </div>
                            <p>Вычисляются частные производные функции потерь по каждому весу:</p>
                            <div class="gradient-formula">
                                $$\frac{\partial L}{\partial w}$$
                            </div>
                        </div>
                    </div>

                    <div class="algorithm-step">
                        <div class="step-header">
                            <div class="step-number">3</div>
                            <div class="step-title">
                                <h4>Обновление весов (Gradient Descent)</h4>
                            </div>
                        </div>
                        <div class="step-content">
                            <p>Каждое соединение корректируется пропорционально градиенту:</p>
                            <div class="update-formula">
                                $$w := w - \eta \cdot \frac{\partial L}{\partial w}$$
                            </div>
                            <div class="parameters-explanation">
                                <div class="param">
                                    <span class="param-symbol">$w$</span>
                                    <span class="param-desc">— текущее значение веса</span>
                                </div>
                                <div class="param">
                                    <span class="param-symbol">$\eta$</span>
                                    <span class="param-desc">— скорость обучения</span>
                                </div>
                                <div class="param">
                                    <span class="param-symbol">$\frac{\partial L}{\partial w}$</span>
                                    <span class="param-desc">— градиент функции потерь по весу</span>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="page-content" id="backprop-page-3" style="display: none;">
                <h3>Как это работает на практике</h3>

                <div class="practical-explanation">
                    <div class="explanation-point">
                        <div class="point-icon">📊</div>
                        <div class="point-content">
                            <h4>Сравнение с правильным ответом</h4>
                            <p>Ошибка на выходе сети сравнивается с правильным ответом. Разница определяет величину
                                корректировки.</p>
                        </div>
                    </div>

                    <div class="explanation-point">
                        <div class="point-icon">🎭</div>
                        <div class="point-content">
                            <h4>Распределение ответственности</h4>
                            <p>Каждый слой получает часть ошибки, которую он «внёс» в общий результат. Более глубокие
                                слои получают меньшую долю ошибки из-за затухания градиентов.</p>
                        </div>
                    </div>

                    <div class="explanation-point">
                        <div class="point-icon">⚖️</div>
                        <div class="point-content">
                            <h4>Принцип пропорциональности</h4>
                            <p>Слои корректируют веса по принципу: <strong>чем больше вклад в ошибку, тем сильнее
                                    коррекция</strong>. Это обеспечивает целенаправленное обучение.</p>
                        </div>
                    </div>
                </div>

                <div class="chain-rule-explanation">
                    <h4>Математическая основа: Цепное правило</h4>
                    <p>Backpropagation основан на цепном правиле дифференцирования сложных функций:</p>
                    <div class="chain-rule-formula">
                        <p>Для функции $f(g(x))$ производная вычисляется как:</p>
                        <div class="formula">
                            $$\frac{df}{dx} = \frac{df}{dg} \cdot \frac{dg}{dx}$$
                        </div>
                        <p>В нейронной сети каждый слой представляет собой функцию, применяемую к выходу предыдущего
                            слоя.</p>
                    </div>
                </div>

                <div class="image-container">
                    <img src="img/backpropagation_detailed.png" alt="Детальная схема backpropagation"
                        class="content-image">
                    <div class="image-caption">Детализированная схема распространения ошибки через слои сети</div>
                </div>
            </div>

            <div class="page-content" id="backprop-page-4" style="display: none;">
                <h3>Преимущества метода</h3>

                <div class="advantages-grid">
                    <div class="advantage-card">
                        <div class="advantage-icon">🏔️</div>
                        <div class="advantage-content">
                            <h4>Обучение глубоких сетей</h4>
                            <p>Позволяет обучать <strong>глубокие сети</strong> с множеством скрытых слоёв, что было
                                невозможно до его изобретения.</p>
                        </div>
                    </div>

                    <div class="advantage-card">
                        <div class="advantage-icon">🤖</div>
                        <div class="advantage-content">
                            <h4>Автоматическое вычисление</h4>
                            <p><strong>Автоматически вычисляет градиенты</strong> для всех весов сети, избавляя от
                                ручного расчёта производных.</p>
                        </div>
                    </div>

                    <div class="advantage-card">
                        <div class="advantage-icon">🔄</div>
                        <div class="advantage-content">
                            <h4>Универсальность</h4>
                            <p><strong>Совместим с любыми функциями активации</strong>, которые дифференцируемы (ReLU,
                                Sigmoid, Tanh, Softmax).</p>
                        </div>
                    </div>
                </div>

                <h3>Ограничения и решения</h3>

                <div class="limitations-solutions">
                    <div class="issue-card">
                        <div class="issue-header">
                            <div class="issue-icon">⚠️</div>
                            <div class="issue-title">
                                <h4>Затухание градиентов (Vanishing Gradient)</h4>
                            </div>
                        </div>
                        <div class="issue-content">
                            <p><strong>Проблема:</strong> В глубоких сетях градиенты могут становиться очень маленькими,
                                что останавливает обучение.</p>
                            <div class="solutions">
                                <h5>Решения:</h5>
                                <ul>
                                    <li>Использование ReLU вместо Sigmoid/Tanh</li>
                                    <li>Правильная инициализация весов (He/Xavier)</li>
                                    <li>Skip-connections (ResNet)</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <div class="issue-card">
                        <div class="issue-header">
                            <div class="issue-icon">💥</div>
                            <div class="issue-title">
                                <h4>Взрыв градиентов (Exploding Gradient)</h4>
                            </div>
                        </div>
                        <div class="issue-content">
                            <p><strong>Проблема:</strong> Градиенты могут становиться очень большими, вызывая
                                нестабильность обучения.</p>
                            <div class="solutions">
                                <h5>Решения:</h5>
                                <ul>
                                    <li>Градиентное clipping (ограничение величины)</li>
                                    <li>Правильная настройка learning rate</li>
                                    <li>Batch Normalization</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>

                <h3>Современные реализации</h3>

                <div class="modern-implementations">
                    <div class="implementation-card">
                        <div class="impl-icon">⚡</div>
                        <div class="impl-content">
                            <h4>Автоматическое дифференцирование</h4>
                            <p>Современные фреймворки (PyTorch, TensorFlow) автоматически вычисляют градиенты используя
                                технику autodiff.</p>
                        </div>
                    </div>

                    <div class="implementation-card">
                        <div class="impl-icon">📊</div>
                        <div class="impl-content">
                            <h4>Вычислительные графы</h4>
                            <p>Операции представляются в виде графа, что позволяет эффективно вычислять производные.</p>
                        </div>
                    </div>

                    <div class="implementation-card">
                        <div class="impl-icon">🚀</div>
                        <div class="impl-content">
                            <h4>Распределённое обучение</h4>
                            <p>Backpropagation эффективно масштабируется на несколько GPU и кластеров.</p>
                        </div>
                    </div>
                </div>

                <div class="historical-note">
                    <h4>Историческая справка</h4>
                    <p>Алгоритм backpropagation был независимо переоткрыт несколько раз. Наиболее известная работа —
                        статья 1986 года Румельхарта, Хинтона и Вильямса, которая популяризировала метод и показала его
                        эффективность для обучения многослойных сетей.</p>
                </div>
            </div>

            <div class="section-navigation">
                <button class="nav-btn" id="backprop-prev-btn"><i class="fas fa-arrow-left"></i> Назад</button>
                <div class="page-indicator" id="backprop-page-indicator">Страница 1 из 4</div>
                <button class="nav-btn" id="backprop-next-btn">Вперед <i class="fas fa-arrow-right"></i></button>
            </div>
        </section>
    </main>

    <script src="js/index.js"></script>
</body>
</html>
